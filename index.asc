= Albertho S. Costa - Engenheiro de Controle e Automação
E-mail <albertho.costa.091@ufrn.edu.br>
:toc: left
:toc-title: Sumário
:doctype: book

== 1. Processamento de Imagens no Domínio Espacial

[.text-justify]
Ferramentas que buscam alterar uma determinada imagem de entrada, de maneira a deixá-la com aspectos mais realçados, suavizados (borramento), ou aspectos desejados de acordo com o processamento aplicado. Nesse caso, as operações são feitas diretamente no plano da imagem.


== 2. Exemplos do implementação de processamento digital de imagens no domínio espacial utilizando openCV:

=== 2.1. MakeFile

[.text-justify]
* Arquivo Makefile que possui regras para compilar as dependências das bibliotecas openCV de forma automática.


[source,Makefile]
.Makefile
----
.SUFFIXES:
.SUFFIXES: .cpp

GCC = g++

.cpp:
	$(GCC) -Wall -Wunused -std=c++11 -O2 $< -o $@ `pkg-config --cflags --libs opencv4`
----

=== 2.2. Helloworld

[.text-justify]
* Exemplo 1: A primeira implementação é de um algoritmo "helloworld" que apresente uma imagem em tons de cinza via terminal, utilizando openCV na linguagem de programação C++. O algoritmo retorna a imagem do Biel na <<biel, figura 1>> vista a seguir.

[source,hello.cpp]
.hello.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv){
  cv::Mat image;
  image = cv::imread(argv[1],cv::IMREAD_GRAYSCALE);
  cv::imshow("image", image);
  cv::waitKey();
  return 0;
}
----

[#biel]
.Biel
image::./image/biel.png[align="center"]

=== 2.3. Pintando Pixels

[.text-justify]
* Exemplo 2: O algoritmo a seguir abre a <<bolhas,figura 2>> (interpretando-a em escala de cinza), e a exibe em uma janela. Após isso, desenha um quadrado preto em uma região pré-estabelecida.
Em seguida, ele irá aguardar que o usuário pressione alguma tecla. Uma vez pressionada a tecla, o programa reabrirá o arquivo da imagem interpretando-a em escala de cores e passará a desenhar um quadrado vermelho na mesma região que foi pré-estabelecida.


[source,pixels.cpp]
.pixels.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>
int main(int, char**){
  cv::Mat image;
  cv::Vec3b val;
  image= cv::imread("bolhas.png",cv::IMREAD_GRAYSCALE);
  if(!image.data)
    std::cout << "nao abriu bolhas.png" << std::endl;
  cv::namedWindow("janela", cv::WINDOW_AUTOSIZE);
  for(int i=200;i<210;i++){
    for(int j=10;j<200;j++){
      image.at<uchar>(i,j)=0;
    }
  }
  cv::imshow("janela", image);  
  cv::waitKey();
  image= cv::imread("bolhas.png",cv::IMREAD_COLOR);
  val[0] = 0;   //B
  val[1] = 0;   //G
  val[2] = 255; //R
  for(int i=200;i<210;i++){
    for(int j=10;j<200;j++){
      image.at<cv::Vec3b>(i,j)=val;
    }
  }
  cv::imshow("janela", image);  
  cv::waitKey();
  return 0;
}
----

[#bolhas]
.Bolhas
image::./image/bolhas.png[]

[#saidabolhas]
.pixels.cpp output
image::./image/saidabolhas.png[]

===  2.4. Negativo

[.text-justify]
* Exemplo 3: O programa seguinte, <<regionscpp,regions.cpp>>, solicita ao usuário as coordenadas de dois pontos P1 e P2 localizados dentro dos limites do tamanho da imagem que lhe for fornecida (ver a <<terminalregions,figura 4>>). Entretanto, a região definida pelo retângulo de vértices opostos definidos pelos pontos P1 e P2 será exibida com o negativo da imagem na região correspondente. A resposta do algorimto pode ser vista na <<regions, figura 5>>.

[#regionscpp]
.regions.cpp
[source,regions.cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int, char**){
  cv::Mat image;
  cv::Vec3b val;
  int xi,yi,xf,yf;

  //Carregando imagem:
  image = cv::imread("biel.png",cv::IMREAD_GRAYSCALE);
  if(!image.data)
    std::cout << "nao abriu biel.png" << std::endl;

  // Descobrindo o tamanho da imagem:
  cv::Size size = image.size();
  std::cout << "Considerando que a imagem tem as seguintes dimensões:" << std::endl;

  // Imprime o tamanho em pixels:
  std::cout << "Largura: " << size.width << " pixels" << std::endl;
  std::cout << "Altura: " << size.height << " pixels" << std::endl;

  // Recebendo valores:
  std::cout << "Defina dois pontos (x,y) opostos de um retângulo que contemple essa dimensão da imagem:" << std::endl;
  std::cout <<"Ponto inicial (X):";
  std::cin >> xi;
  std::cout <<"Ponto inicial (Y):";
  std::cin >> yi;
  std::cout <<"Ponto final (X):";
  std::cin >> xf;
  std::cout <<"Ponto final (Y):";
  std::cin >> yf;

  cv::imshow("janela", image);  
  cv::waitKey();

  image = cv::imread("biel.png",cv::IMREAD_GRAYSCALE);
  cv::namedWindow("janela", cv::WINDOW_AUTOSIZE);

  for(int i=xi;i<=xf;i++){
    for(int j=yi;j<=yf;j++){
        image.at<uchar>(i,j) = 255 - (image.at<uchar>(i,j));
    }
  }

  cv::imshow("janela", image);  
  cv::waitKey();

  return 0;
}
----

[#terminalregions]
.Terminal: regions.cpp 

image::./image/terminalregions.png[]

[#regions]
.regions.cpp Output

image::./image/saidaregions.png[]

=== 2.5. Trocando Quadrantes

[.text-justify]
* Exemplo 4: O quarto exemplo faz a troca de quadrantes diagonal na imagem. Esse procedimento é uma etapa importante em processamento de imagens no domínio da frequência, e será implementado novamente mais na frente. É explorado no algoritmo <<trocarregioes,trocarregioes.cpp>> o uso da classe Mat e seus construtores para criar as regiões que serão trocadas.

[#trocarregioes]
.trocarregioes.cpp
[source,trocaregioes.cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int, char **)
{
    cv::Mat image;
    cv::Vec3b val;

    // Carregando imagem:
    image = cv::imread("biel.png", cv::IMREAD_GRAYSCALE);
    if (!image.data)
        std::cout << "nao abriu biel.png" << std::endl;

    // Descobrindo o tamanho da imagem:
    cv::Size size = image.size();
    std::cout << "Considerando que a imagem tem as seguintes dimensões:" << std::endl;

    // Imprime o tamanho em pixels:
    std::cout << "Largura: " << size.width << " pixels" << std::endl;
    std::cout << "Altura: " << size.height << " pixels" << std::endl;
    cv::imshow("janela 1", image);
    cv::waitKey();

    // Definindo os 4 quadrantes com submatrizes na classe "Mat":
    int largura = size.width / 2;
    int altura = size.height / 2;
    cv::Mat quadrante1 = image(cv::Rect(0, 0, largura, altura));
    cv::Mat quadrante2 = image(cv::Rect(largura, 0, largura, altura));
    cv::Mat quadrante3 = image(cv::Rect(0, altura, largura, altura));
    cv::Mat quadrante4 = image(cv::Rect(largura, altura, largura, altura));

    // Usando o método "hconcat" da classe "Mat" para concatentar os quadrantes opostos 
    // horizontalmente em duas linhas, e o método "vconcat" para concatenar as linhas com
    // os quadrantes já reorganizados:

    cv::Mat linha1, linha2, imagemFinal;
    cv::hconcat(quadrante4, quadrante3, linha1);
    cv::hconcat(quadrante2, quadrante1, linha2);
    cv::vconcat(linha1, linha2, imagemFinal);

    imwrite("saidaquadrantes.png", imagemFinal); 

    cv::imshow("janela 2", imagemFinal);
    cv::waitKey();

    return 0;
}
----

[.text-justify]
A imagem que foi usada como entrada para o algoritmo é a do <<biel,Biel>>. A saída mostra os quadrantes diagonais trocados. Veja a <<saidaquadrantes,figura 6>>.

[#saidaquadrantes]
.trocaregioes.cpp Output
image::./image/saidaquadrantes.png[]

=== 2.6. PNG versus YML

[.text-justify]
* Exemplo 5: O programa a seguir gera uma imagem de dimensões 256x256 pixels contendo uma senóide de 4 períodos com amplitude de 127 desenhada na horizontal. Grava a imagem no formato PNG que possui valores inteiros, e no formato YML com valores em pontos flutuantes. Por último é feita uma comparação entre os arquivos gerados, extraindo uma linha de cada imagem gravada e comparando a diferença entre elas. É possível observar no gráfico da <<ymlxpng,figura 8>> gerado que a diferença entre as duas imagens é pequena, considerando que os valores são menores que 1, e os pixeis representam 256 possíveis tons de cinza. Note que haveria uma mudança significativa na visualização da imagem PNG gerada, se o arredondamento resultante da imagem YML mudasse mais de 5 tons de pixeis, o que não ocorre nessa situação. O algoritmo gera também dois arquivos no formato TXT, e o gráfico foi gerado no excel.

.filestorage.cpp
[source,filestorage.cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <sstream>
#include <string>
#include <fstream>
int SIDE = 256;
int PERIODOS = 8;

int main(int argc, char **argv)
{
  std::stringstream ss_img, ss_yml;
  cv::Mat image;
  ss_yml << "senoide-" << SIDE << ".yml";
  image = cv::Mat::zeros(SIDE, SIDE, CV_32FC1);
  cv::FileStorage fs(ss_yml.str(), cv::FileStorage::WRITE);
  
  for (int i = 0; i < SIDE; i++)
  {
    for (int j = 0; j < SIDE; j++)
    {
      image.at<float>(i, j) = 127 * sin(2 * M_PI * PERIODOS * j / SIDE) + 128;
    }
  }

  // Criando um .txt referente à imagem .yml
  std::ofstream outFileyml("imageyml.txt");
  if (!outFileyml.is_open())
  {
    std::cout << "Erro ao criar o arquivo de saída." << std::endl;
    return -1;
  }
  for (int i = 0; i < image.rows; i++)
  {
    for (int j = 0; j < image.cols; j++)
    {
      float pixelValues = image.at<float>(i, j);
      outFileyml << pixelValues << " ";
    }
    outFileyml << std::endl;
  }
  outFileyml.close();
  fs << "mat" << image;
  fs.release();
  cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
  image.convertTo(image, CV_8U);
  ss_img << "senoide-" << SIDE << ".png";
  cv::imwrite(ss_img.str(), image);
  fs.open(ss_yml.str(), cv::FileStorage::READ);
  fs["mat"] >> image;
  cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
  image.convertTo(image, CV_8U);
  
  // Criando um .txt referente à imagem .png
  std::ofstream outFilepng("imagePNG.txt");
  if (!outFilepng.is_open())
  {
    std::cout << "Erro ao criar o arquivo de saída." << std::endl;
    return -1;
  }
  for (int i = 0; i < image.rows; i++)
  {
    for (int j = 0; j < image.cols; j++)
    {
      int pixelValue = image.at<uchar>(i, j);
      outFilepng << pixelValue << " ";
    }
    outFilepng << std::endl;
  }
  outFilepng.close();
  cv::imshow("image", image);
  cv::waitKey();
  
  return 0;
}
----

[#senoide]
.Senoide Gerada
image::./image/senoidePNG-256.png[]

[#ymlxpng]
.Gráfico da Diferença
image::./image/pngxyml.png[]

=== 2.7. Criptografia por Esteganometria

[.text-justify]
* Exemplo 6: O algoritmo a seguir realiza uma descriptografia de uma imagem que passou por um processo de esteganografia. Lembre-se que os bits menos significativos dos pixels da imagem fornecida deverão compor os bits mais significativos dos pixels da imagem recuperada. O programa recebe como parâmetros de linha de comando o nome da imagem resultante da esteganografia (<<cripto,Figura 9>>).

.descriptesteganometria.cpp
[source,descriptesteganometria.cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char**argv) {
  cv::Mat imagemPortadora, imagemFinal;
  cv::Vec3b valPortadora;
  int nbits = 3;
  imagemPortadora = cv::imread(argv[1], cv::IMREAD_COLOR);
  std::string imagemDecodificada;
  std::cout << "Digite o nome que queres para a imagem resultante da decodificação (.png):" << std::endl;
  std::cin >> imagemDecodificada;
  if (imagemPortadora.empty()) {
    std::cout << "imagem nao carregou corretamente" << std::endl;
    return (-1);
  }

  imagemFinal = imagemPortadora.clone();
  for (int i = 0; i < imagemPortadora.rows; i++) {
    for (int j = 0; j < imagemPortadora.cols; j++) {
      valPortadora = imagemPortadora.at<cv::Vec3b>(i, j);
      valPortadora[0] = valPortadora[0] << (8-nbits); // Desloca 5 vezes à esquerda os bits da imagemPortadora[0]
      valPortadora[1] = valPortadora[1] << (8-nbits); // Desloca 5 vezes à esquerda os bits da imagemPortadora[1]
      valPortadora[2] = valPortadora[2] << (8-nbits); // Desloca 5 vezes à esquerda os bits da imagemPortadora[2]
      imagemFinal.at<cv::Vec3b>(i, j) = valPortadora; 
      // Ex: [11111555] -> [11115550] -> [11155500] ... -> [55500000]
      // Dessa forma, os 3 bits escondidos nos 3 menos significativos
      // se tornam os 3 mais significativos
    }
  }

  imwrite(imagemDecodificada, imagemFinal);
  cv::imshow("image", imagemPortadora);
  cv::waitKey();
  cv::imshow("image", imagemFinal);
  cv::waitKey();

  return 0;
}
----

[#cripto]
.Imagem criptografada por esteganometria
image::./image/desafio-esteganografia.png[]

[#steg]
.Imagem Descriptografada
image::./image/estegsaida.png[]

=== 2.8. Algoritmo de Floodfill

[.text-justify]
* Exemplo 7: Uma implementação interessante em processamento digital de imagens é o cálculo de objetos presentes em uma determinada cena. A identificação das bolhas na <<bolhas,figura 2>> (regiões brancas) pode variar de acordo com a consideração que é feita para os objetos (bolhas). Dessa forma, o algoritmo a seguir busca inicialmente excluir os objetos na borda da imagem, após isso ele identifica os objetos com "buracos" (bolhas com regiões pretas dentro), e retorna no terminal a quantidade de bolhas nas bordas, de buracos e das bolhas resultantes na imagem. Para isso, foi utilizado o algoritmo floodfill.

.bolhascombolhas.cpp
[source,bolhascombolhas.cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;

int main(int argc, char **argv)
{
    cv::Mat image;
    int width, height;
    int nobjects, edgeobjects, holeobjects;
    cv::Point p;
    image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);
    if (!image.data)
    {
        std::cout << "imagem nao carregou corretamente\n";
        return (-1);
    }
    cv::imshow("image", image);
    cv::waitKey();
    width = image.cols;
    height = image.rows;
    std::cout << width << "x" << height << std::endl;
    p.x = 0;
    p.y = 0;

    // busca objetos presentes nas bordas e pinta de preto
    edgeobjects = 0;
    for (int i = 0; i < height; i++)
    {
        for (int j = 0; j < width; j++)
        {
            if (i == 0 || i == (height - 1) || j == 0 || j == (width - 1))
            {
                if (image.at<uchar>(i, j) == 255)
                {
                    // Achou um objeto (bolha) na borda
                    // Para o floodfill as coordenadas
                    // x e y são trocadas.
                    p.x = j;
                    p.y = i;
                    edgeobjects++;
                    cv::floodFill(image, p, 0);
                }
            }
        }
    }
    cv::imshow("image", image);
    cv::imwrite("sembordas.png", image);
    cv::waitKey();

    // busca objetos com bolhas internas
    // Muda a cor do fundo preto para o tom
    // de cinza 150 (uma vez que ele começa a
    // percorrer pela borda e como as bolhas
    // das bordas sumiram, o primeiro ponto
    // preto encontrado será o fundo)

    p.x = 0;
    p.y = 0;
    cv::floodFill(image, p, 150);
    holeobjects = 0;
    cv::imshow("image", image);
    cv::imwrite("mudacor.png", image);
    cv::waitKey();
    for (int i = 0; i < height; i++)
    {
        for (int j = 0; j < width; j++)
        {
            if (image.at<uchar>(i, j) == 0)
            {
                // Procura o próximo ponto preto
                // que será, necessariamente, uma 
                // bolha interna, uma vez que o
                // fundo não é mais preto. Transforma
                // essa região em branco, eliminando
                // a bolha interna
                p.x = j;
                p.y = i;
                holeobjects++;
                cv::floodFill(image, p, 255);
            }
        }
    }
    cv::imshow("image", image);
    cv::imwrite("semburacos.png", image);
    cv::waitKey();

    // Muda a cor do fundo do tom de cinza 150 para 
    // preto (0)
    p.x = 0;
    p.y = 0;
    cv::floodFill(image, p, 0);
    cv::imshow("image", image);
    cv::imwrite("voltacor.png", image);
    cv::waitKey();

    // busca objetos presentes
    nobjects = 0;
    for (int i = 0; i < height; i++)
    {
        for (int j = 0; j < width; j++)
        {
            if (image.at<uchar>(i, j) == 255)
            {
                // achou um objeto
                nobjects++;
                // para o floodfill as coordenadas
                // x e y são trocadas.
                p.x = j;
                p.y = i;
                // preenche o objeto com o contador
                cv::floodFill(image, p, nobjects);
            }
        }
    }
    std::cout << "a figura tinha " << edgeobjects << " bolhas nas bordas\n";
    std::cout << "a figura tinha " << holeobjects << " buracos\n";
    std::cout << "a figura tem " << nobjects << " bolhas\n";
    cv::imshow("image", image);
    cv::imwrite("labeling.png", image);
    cv::waitKey();

    return 0;
}
----

[#passo1]
.Passo 01
image::./image/sembordas.png[]

[#passo2]
.Passo 02
image::./image/mudacor.png[]

[#passo3]
.Passo 03
image::./image/semburacos.png[]

[#passo4]
.Passo 04
image::./image/voltacor.png[]

[#passo5]
.Passo 05
image::./image/labeling.png[]

[#terminalfloodfill]
.terminal Output
image::./image/terminaloutput.png[]

=== 2.9. Equalização de Histogramas

[.text-justify]
* Exemplo 8: A próxima implementação utiliza dos conceitos de equalização de histogramas para melhorar a distribuição de tons de cinza em uma determinada imagem. O algoritmo retorna continuamente duas janelas de visualização da webcam do computador, uma é relativa à imagem original (<<image,figura 17>>) em tons de cinza, e a outra refere-se à essa imagem equalizada (<<imagequalized,figura 18>>). Ao pressionar "ESC" o programa finaliza e retorna a captura das imagens no momento ligeiramente antes de pressionar a tecla.

.equalize.cpp
[source,equalize.cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv){
  cv::Mat image,grayFrame,equalizedImg;
  int width, height;
  cv::VideoCapture cap;
  std::vector<cv::Mat> planes;
  cv::Mat hist;
  int nbins = 64;
  float range[] = {0, 255};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
  int key;

  cap.open(0);
  
  if(!cap.isOpened()){
    std::cout << "cameras indisponiveis";
    return -1;
  }
  
  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);  
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

  std::cout << "largura = " << width << std::endl;
  std::cout << "altura  = " << height << std::endl;

  int histw = nbins, histh = nbins/2;
  cv::Mat histImg(histh, histw, CV_8UC3, cv::Scalar(0));

  while(1){
    cap >> image;

    cv::Mat grayFrame;
    cv::cvtColor(image, grayFrame, cv::COLOR_BGR2GRAY);

    //cv::split (grayFrame, planes);
    cv::calcHist(&grayFrame, 1, 0, cv::Mat(), hist, 1,
                 &nbins, &histrange,
                 uniform, acummulate);
    
    cv::normalize(hist, hist, 0, histImg.rows, cv::NORM_MINMAX, -1, cv::Mat());

    // Equalizar o histograma
    cv::Mat equalizedImg;
    cv::equalizeHist(grayFrame, equalizedImg);
    
    histImg.setTo(cv::Scalar(0));
    
    for(int i=0; i<nbins; i++){
      cv::line(histImg,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(hist.at<float>(i))),
               cv::Scalar(0, 0, 255), 1, 8, 0);
    }
    cv::imshow("image", grayFrame);
    cv::imshow("image equalized", equalizedImg);
    key = cv::waitKey(30);
    if(key == 27)
    {
      cv::imwrite("image.png", grayFrame);
      cv::imwrite("imagequalized.png", equalizedImg);
      break;
    } 
  }
  return 0;
}
----

[#image]
.Imagem Original
image::./image/image.png[]

[#imagequalized]
.Imagem Equalizada
image::./image/imagequalized.png[]

[.text-justify]
Como pode ser observado, a equalização revela detalhes antes escondidos pela baixa iluminação, como a mão, a barba e alguns contornos.

=== 2.10. Filtragem no Domínio Espacial

[.text-justify]
* Exemplo 9: A filtragem no domínio espacial é uma ferramenta que busca alterar uma determinada imagem de entrada, de maneira a deixá-la com aspectos mais realçados, suavizados (borramento), ou aspectos desejados de acordo com o filtro utilizado. Nesse caso, as operações são feitas diretamente no plano da imagem. É possível realizar a filtragem através da convolução bidimensional de uma máscara (matriz de tamanho ímpar) com a matriz que representa a imagem a ser filtrada. A fórmula da convolução pode ser observada na <<convolucao,figura 19>>.

[#convolucao]
.Convolução bidimensional
image::./image/convolucao.png[]

[.text-justify]
* Exemplo 9 (Continuação): Baseado nisso, o algoritmo a seguir foi desenvolvido para realizar o filtro laplaciano do gaussiano, onde a princípio aplica-se a máscara gaussiana na imagem de entrada, e em seguida aplica a máscara laplaciana. Além desse filtro, também é possível aplicar uma série de filtros diferentes: filtro da média; gaussiano; sobel horizontal; sobel vertical; sobel +45°; -45°; laplaciano e boost. O usuário determina qual filtro especificamente deseja aplicar à imagem de entrada via terminal, de acordo com a letra digitada (ver switch case no algoritmo <<lapgaus>>).

[#lapgaus]
.lapgauss.cpp
[source,lapgauss.cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int, char **)
{
    cv::Mat image;

    //image = cv::imread("imgsalepimenta.png", cv::IMREAD_GRAYSCALE);
    image = cv::imread("sobel.png", cv::IMREAD_GRAYSCALE);


    if (!image.data)
        std::cout << "nao abriu imgsalepimenta.png" << std::endl;

    cv::imshow("Original", image);

    float media[] = {0.1111, 0.1111, 0.1111, 0.1111, 0.1111,
                     0.1111, 0.1111, 0.1111, 0.1111};
    float gauss[] = {0.0625, 0.125, 0.0625, 0.125, 0.25,
                     0.125, 0.0625, 0.125, 0.0625};
    float vertical [] = {-1, 0, 1, -2, 0, 2, -1, 0, 1};     // Máscara de Sobel vertical
    float horizontal [] = {-1, -2, -1, 0, 0, 0, 1, 2, 1};   // Máscara de Sobel horizontal
    float mais45 [] = {0, 1, 2, -1, 0, 1, -2, -1, 0};       // Máscara de Sobel +45°
    float menos45 [] = {-2, -1, 0, -1, 0, 1, 0, 1, 2};      // Máscara de Sobel -45°
    float laplacian[] = {0, -1, 0, -1, 4, -1, 0, -1, 0};
    float boost[] = {0, -1, 0, -1, 5.2, -1, 0, -1, 0};      // Máscara de nitidez

    cv::Mat image32f, imageFiltered, secondFilteredimage;
    cv::Mat mask(3, 3, CV_32F);
    cv::Mat result;
    int absolut, laplgauss = 0;
    char key;

    mask = cv::Mat(3, 3, CV_32F, media);
    absolut = 1; // calcs abs of the image
    
    // Loop para o programa rodar até que ESC seja pressionada
    while(key != 27){
        
    key = (char)cv::waitKey();
    switch (key)
    {
    case 'a':
        absolut = !absolut;
        laplgauss = 0;
        break;
    case 'm':
        mask = cv::Mat(3, 3, CV_32F, media);
        laplgauss = 0;
        break;
    case 'g':
        mask = cv::Mat(3, 3, CV_32F, gauss);
        laplgauss = 0;
        break;
    case 'h':
        mask = cv::Mat(3, 3, CV_32F, horizontal);
        laplgauss = 0;
        break;
    case 'v':
        mask = cv::Mat(3, 3, CV_32F, vertical);
        laplgauss = 0;
        break;
    case 'j':
        mask = cv::Mat(3, 3, CV_32F, mais45);
        laplgauss = 0;
        break;
    case 'k':
        mask = cv::Mat(3, 3, CV_32F, menos45);
        laplgauss = 0;
        break;
    case 'l':
        mask = cv::Mat(3, 3, CV_32F, laplacian);
        laplgauss = 0;
        break;
    case 'b':
        mask = cv::Mat(3, 3, CV_32F, boost);
        laplgauss = 0;
        break;
    case 'p':
        // Opção para o filtro LoG (Laplaciano do Gaussiano)
        laplgauss = 1;
        break;
    default:
        break;
    }

    // Caso a seleção seja Laplaciano do Gaussiano
    if (laplgauss == 1)
    {
        image.convertTo(image32f, CV_32F);

        // Aplicando o filtro gaussiano
        mask = cv::Mat(3, 3, CV_32F, gauss);
        cv::filter2D(image32f, imageFiltered, image32f.depth(),
                     mask,
                     cv::Point(1, 1), 0);
        // Aplicando o filtro laplaciano
        mask = cv::Mat(3, 3, CV_32F, laplacian);
        cv::filter2D(imageFiltered, secondFilteredimage, image32f.depth(),
                     mask,
                     cv::Point(1, 1), 0);

        if (absolut)
        {
            secondFilteredimage = cv::abs(secondFilteredimage);
        }

        secondFilteredimage.convertTo(result, CV_8U);
    }
    else if (laplgauss == 0)
    {   
        image.convertTo(image32f, CV_32F);

        cv::filter2D(image32f, imageFiltered, image32f.depth(),
                     mask,
                     cv::Point(1, 1), 0);
        if (absolut)
        {
            imageFiltered = cv::abs(imageFiltered);
        }

        imageFiltered.convertTo(result, CV_8U);
    }

    cv::imshow("Filtrado", result);
    }
    //cv::waitKey();
    return 0;
}
----

[.text-justify]
* Exemplo 9 (Continuação): A imagem de entrada <<salepimenta, figura 20>>, retirada do livro de Processamento Digital de Imagens de Rafael C. Gonzalez, foi utilizada para avaliar os efeitos de suavização do ruido na aplicação dos filtros mostrados acima. Vale salientar que o filtro ideal para esse tipo de ruido é o filtro da mediana.

[#salepimenta]
.Ruído Sal e Pimenta (processamento digital de imagens - Rafael c. gonzalez)
image::./image/imgsalepimenta.png[]

[.text-justify]
* Exemplo 9 (Continuação): As respostas da media, laplaciano, gaussiano e laplaciano do gaussiano são vistas, respectivamente, nas seguintes figuras: <<media,figura 21>>, <<gaussiano,figura 22>>, <<laplaciano,figura 23>>, <<log,figura 24>>.

[#media]
.Filtragem com máscara da média 
image::./image/media.png[]

[#gaussiano]
.Filtragem com máscara gaussiana
image::./image/gaussiano.png[]

[#laplaciano]
.Filtragem com máscara laplaciana
image::./image/laplaciano.png[]

[#log]
.Filtragem com máscara laplaciano do gaussiano
image::./image/log.png[]

[.text-justify]
* Exemplo 9 (Continuação): Note que o filtro laplaciano do gaussiano apresenta detalhes de contornos na imagem, mas com uma quantidade de ruído bem menor que o filtro somente laplaciano. Isso ocorre pela suavização feita pelo filtro gaussiano antes da aplicação do laplaciano. Além disso, é notório o borramento causado pelos filtros da média e gaussiano. Para reduzir a suavização ocasionada pelo filtro da média, é possível realizar a média ponderada, definindo na máscara pesos maiores para a sua região central (veja a <<mascaramedia,figura 25>> retirada do livro de Rafael C. Gonzalez. A letra "a" é a máscara da média e "b" da média ponderada).

[#mascaramedia]
.Máscaras da média aritmética (a) e média ponderada (b) (processamento digital de imagens - Rafael c. gonzalez)
image::./image/filtrodamedia.png[]

=== 2.11. Algoritmo de Tiltshif

[.text-justify]
* Exemplo 10: Tiltshift




[#s_ProcessamentodeImagensnoDomíniodafrequencia]
== 3. Processamento de Imagens no Domínio da Frequência

[.text-justify]
Antes de inciar o tópico de Processamento de Imagens no Domínio da Frequência, é interessante comentar sobre a importância da transformada discreta de Fourier (DFT) nessas aplicações, mais especificamente, a transformada discreta de Fourier de duas dimensões (<<DFT, figura 26>>).

[#DFT]
.Transformada Discreta de Fourier 2D (processamento digital de imagens - Rafael c. gonzalez)
image::./image/DFT.png[]

[#IDFT]
.Transformada Discreta de Fourier 2D Inversa (processamento digital de imagens - Rafael c. gonzalez)
image::./image/IDFT.png[]

[.text-justify]
A transformada discreta de Fourier bidimensional é muito importante para o processamento de imagens, pois permite discretizar um sinal contínuo em funções senoidais ponderadas. No caso das imagens digitais, a DFT permite visualizar aspectos periódicos através de sua resposta em magnitude (<<espectromag, figura 28>>), sendo possível assim, elimitar ruidos com características periódicas. Algumas características da transformada discreta de Fourier são levadas em consideração para a sua implementação em algoritmos de processamento digital de imagens. Por exemplo, considerando que a transformada e sua inversa são infinitamentes periódicas, é possível centralizar um período completo da transformada  deslocando os dados para o centro da imagem. Uma vez que as componentes de altas frequência da matriz da imagem encontram-se nas suas extremidades, alterar os quadrantes da matriz (de forma semelhante ao deslocamento visto na <<saidaquadrantes, figura 6>>) permite uma fácil visualização e filtragem dessas componentes, as quais podem representar os ruídos periódicos presentes.

[#espectromag]
.Espectro em Magnitude (processamento digital de imagens - Rafael c. gonzalez)
image::./image/espectrodefourier(magnitude).png[]

[.text-justify]
Além da resposta em magnitude (espectro em magnitude), a transformada também pode retornar o Ângulo de Fase (espectro em fase) (<<angulodefase, figura 29>>). Esse pode ser muito útil em algoritmos de rastreamento de contornos, que serão vistos posteriormente.

[#angulodefase]
.Ângulo de Fase (processamento digital de imagens - Rafael c. gonzalez)
image::./image/angulodefase(magnitude).png[]

[.text-justify]
Levando em consideração os conceitos sobre a DFT, para realizar a filtragem de imagens no domínio da frequência e retornar a imagem no domínio de visualização, basta calcular a inversa da DFT com a máscara utilizada (ver <<filtragemfreq, figura 30>>).

[#filtragemfreq]
.Filtragem no Domínio da Frequência (processamento digital de imagens - Rafael c. gonzalez)
image::./image/filtragemFreqEq.png[]

[.text-justify]
Entre os tipos de filtros utilizados, podem-se citar os filtros low-pass e high-pass. Ao atenuar altas frequências (low-pass) propõe uma diminuição visual dos pontos de grandes transições de intensidades em uma imagem, deixando-a borrada. Já, ao filtrar baixas frequências (high-pass) ocorre o realce dos pontos de grandes transições de intensidades, mas deixa a imagem resultante com um menor contraste.

[#s_exemplos2]
== 4. Exemplos do implementação de processamento digital de imagens no domínio espacial utilizando openCV:

[#s_11]
=== 4.1. Transformada Discreta de Fourier

[.text-justify]
* Exemplo 11: O algoritmo a seguir, utiliza a <<senoide,figura 7>> da senoide, e calcula os seus espectros em magnitude e em fase.

[#dftimage.cpp]
.dftimage.cpp
[source,dftimage.cpp]
----
#include <iostream>
#include <vector>
#include <opencv2/opencv.hpp>

void swapQuadrants(cv::Mat &image)
{
  cv::Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para o maior
  // tamanho par possivel (-2 = 1111...1110)
  image = image(cv::Rect(0, 0, image.cols & -2, image.rows & -2));

  int centerX = image.cols / 2;
  int centerY = image.rows / 2;

  // rearranja os quadrantes da transformada de Fourier de forma que
  // a origem fique no centro da imagem
  // A B   ->  D C
  // C D       B A
  A = image(cv::Rect(0, 0, centerX, centerY));
  B = image(cv::Rect(centerX, 0, centerX, centerY));
  C = image(cv::Rect(0, centerY, centerX, centerY));
  D = image(cv::Rect(centerX, centerY, centerX, centerY));

  // swap quadrants (Top-Left with Bottom-Right)
  A.copyTo(tmp);
  D.copyTo(A);
  tmp.copyTo(D);

  // swap quadrant (Top-Right with Bottom-Left)
  C.copyTo(tmp);
  B.copyTo(C);
  tmp.copyTo(B);
}

int main(int argc, char **argv)
{
  cv::Mat image, padded, complexImage;
  std::vector<cv::Mat> planos;

  image = imread(argv[1], cv::IMREAD_GRAYSCALE);
  if (image.empty())
  {
    std::cout << "Erro abrindo imagem" << argv[1] << std::endl;
    return EXIT_FAILURE;
  }

  // expande a imagem de entrada para o melhor tamanho no qual a DFT pode ser
  // executada, preenchendo com zeros a lateral inferior direita.
  int dft_M = cv::getOptimalDFTSize(image.rows);
  int dft_N = cv::getOptimalDFTSize(image.cols);
  cv::copyMakeBorder(image, padded, 0, dft_M - image.rows, 0, dft_N - image.cols, cv::BORDER_CONSTANT, cv::Scalar::all(0));

  // prepara a matriz complexa para ser preenchida
  // primeiro a parte real, contendo a imagem de entrada
  planos.push_back(cv::Mat_<float>(padded));
  // depois a parte imaginaria com valores nulos
  planos.push_back(cv::Mat::zeros(padded.size(), CV_32F));

  // combina os planos em uma unica estrutura de dados complexa
  cv::merge(planos, complexImage);

  // calcula a DFT
  cv::dft(complexImage, complexImage);
  swapQuadrants(complexImage);

  // planos[0] : Re(DFT(image)
  // planos[1] : Im(DFT(image)
  cv::split(complexImage, planos);

  // calcula o espectro de magnitude e de fase (em radianos)
  cv::Mat magn, fase;
  cv::cartToPolar(planos[0], planos[1], magn, fase, false);
  cv::normalize(fase, fase, 0, 1, cv::NORM_MINMAX);

  // caso deseje apenas o espectro de magnitude da DFT, use:
  cv::magnitude(planos[0], planos[1], magn);

  // some uma constante para evitar log(0)
  // log(1 + sqrt(Re(DFT(image))^2 + Im(DFT(image))^2))
  magn += cv::Scalar::all(1);

  // calcula o logaritmo da magnitude para exibir
  // com compressao de faixa dinamica
  log(magn, magn);
  cv::normalize(magn, magn, 0, 1, cv::NORM_MINMAX);

  // exibe as imagens processadas
  cv::imshow("Imagem", image);
  cv::imshow("Espectro de magnitude", magn);
  cv::imwrite("mag.png", magn);
  cv::imshow("Espectro de fase", fase);
  cv::imwrite("fase.png", fase);

  cv::waitKey();
  return EXIT_SUCCESS;
}
----

[#s_12]
=== 4.2. Filtro Homomórfico
[.text-justify]
* Exemplo 11 (Continuação): As respectivas respostas podem ser vistas a seguir (<<mag,figura 31>> e <<fase,figura 32>>).

[#mag]
.Magnitude Output
image::./image/mag.png[]

[#fase]
.Fase Output
image::./image/fase.png[]

[.text-justify]
* Exemplo 12: A próxima implementação diz respeito ao filtro homomórfico. O filtro homomórfico tem a intenção de melhorar a iluminação irregular de imagens. O algoritmo foi feito considerando o processamento de imagens em tons de cinza.

[#filtrohomomorfico.cpp]
.filtrohomomorfico.cpp
[source,filtrohomomorfico.cpp]
----
#include <iostream>
#include <vector>
#include <opencv2/opencv.hpp>

void swapQuadrants(cv::Mat &image)
{
  cv::Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho ímpar, recorta a região para o maior
  // tamanho par possível (-2 = 1111...1110)
  image = image(cv::Rect(0, 0, image.cols & -2, image.rows & -2));

  int centerX = image.cols / 2;
  int centerY = image.rows / 2;

  // rearranja os quadrantes da transformada de Fourier de forma que
  // a origem fique no centro da imagem
  // A B   ->  D C
  // C D       B A
  A = image(cv::Rect(0, 0, centerX, centerY));
  B = image(cv::Rect(centerX, 0, centerX, centerY));
  C = image(cv::Rect(0, centerY, centerX, centerY));
  D = image(cv::Rect(centerX, centerY, centerX, centerY));

  // swap quadrantes (Top-Left with Bottom-Right)
  A.copyTo(tmp);
  D.copyTo(A);
  tmp.copyTo(D);

  // swap quadrante (Top-Right with Bottom-Left)
  C.copyTo(tmp);
  B.copyTo(C);
  tmp.copyTo(B);
}

void makeFilter(const cv::Mat &image, cv::Mat &filter)
{
  cv::Mat_<float> filter2D(image.rows, image.cols);
  int centerX = image.cols / 2;
  int centerY = image.rows / 2;
  float gammaH = 1.0; // ajuste para realce de iluminação
  float gammaL = 0.5; // ajuste para realce de contraste
  float c = 1.0;      // constante de realce

  for (int i = 0; i < image.rows; i++)
  {
    for (int j = 0; j < image.cols; j++)
    {
      float D = sqrt(pow(i - centerY, 2) + pow(j - centerX, 2));
      // H ( u , v ) = ( γ H − γ L )[ 1 − e − c [ D ( u , v )/ D 0 ] ] + γ L (Gonzales pag. 191)
      float H = (gammaH - gammaL) * (1.0 - exp(-c * pow(D, 2) / pow(centerX, 2))) + gammaL;
      filter2D.at<float>(i, j) = H;
    }
  }

  cv::Mat planes[] = {filter2D, cv::Mat::zeros(filter2D.size(), CV_32F)};
  cv::merge(planes, 2, filter);
}

int main(int argc, char **argv)
{
  cv::Mat image, padded, complexImage;
  std::vector<cv::Mat> planos;

  image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);
  if (image.empty())
  {
    std::cout << "Erro abrindo imagem " << argv[1] << std::endl;
    return EXIT_FAILURE;
  }

  // expande a imagem de entrada para o melhor tamanho no qual a DFT pode ser
  // executada, preenchendo com zeros a lateral inferior direita.
  int dft_M = cv::getOptimalDFTSize(image.rows);
  int dft_N = cv::getOptimalDFTSize(image.cols);
  cv::copyMakeBorder(image, padded, 0, dft_M - image.rows, 0, dft_N - image.cols, cv::BORDER_CONSTANT, cv::Scalar::all(0));

  // prepara a matriz complexa para ser preenchida
  // primeiro a parte real, contendo a imagem de entrada
  planos.push_back(cv::Mat_<float>(padded));
  // depois a parte imaginária com valores nulos
  planos.push_back(cv::Mat::zeros(padded.size(), CV_32F));

  // combina os planos em uma única estrutura de dados complexa
  cv::merge(planos, complexImage);

  // calcula a DFT
  cv::dft(complexImage, complexImage);
  swapQuadrants(complexImage);

  // cria o filtro homomórfico e aplica a filtragem de frequência
  cv::Mat filter;
  makeFilter(complexImage, filter);
  cv::mulSpectrums(complexImage, filter, complexImage, 0);

  // calcula a DFT inversa
  swapQuadrants(complexImage);
  cv::idft(complexImage, complexImage);

  // planos[0] : Re(DFT(image))
  // planos[1] : Im(DFT(image))
  cv::split(complexImage, planos);

  // recorta a imagem filtrada para o tamanho original
  // selecionando a região de interesse (ROI)
  cv::Rect roi(0, 0, image.cols, image.rows);
  cv::Mat result = planos[0](roi);

  // normaliza a parte real para exibição
  cv::normalize(result, result, 0, 1, cv::NORM_MINMAX);

  cv::imshow("Imagem original", image);
  cv::imshow("Imagem filtrada", result);
  cv::imwrite("filtro_homomorfico.png", result * 255);

  cv::waitKey();
  return EXIT_SUCCESS;
}
----

[.text-justify]
* Exemplo 12 (continuação): Considerando a imagem do Biel (<<biel,figura 1>>) como entrada, veja na <<filtro_homomorfico,figura 33>> a saída do filtro homomórfico com a correção da iluminação.

[#filtro_homomorfico]
.Relação entre a entrada e saída do algoritmo do Filtro Homomórfico.
image::./image/homomorfico.png[]

[#s_Segmentaçãodeimagens]
== 5. Segmentação de Imagens

[.text-justify]
A segmentação de uma determinada imagem se trata da divisão de áreas dentro da mesma, de acordo com a necessidade de aplicação. Essa divisão normalmente é feita de acordo com dois possíveis quesitos: descontinuidade ou similaridade.
As detecções abruptas na imagem podem ser obtidas através da derivada.

[.text-justify]
** Derivada ordem 1: Produzem bordas mais grossas na detecção.

[.text-justify]
** Derivada ordem 2: Produzem bordas mais finas e resposta mais forte aos detalhes finos (linhas, pontos e ruidos); em transições de rampa e degrau de intensidade possui uma resposta de bordas duplas; o seu sinal pode ser usado para determinar se a transição é de claro para escuro ou de escuro para claro.

[.text-justify]
Veja a comparação feita no livro do Gonzalez, que trata a diferença entre os efeitos das duas derivadas considerando níveis distintos do ruído gaussiano.

[#bordasderivadas]
.Resposta das derivadas para diferentes níveis de intensidade do ruido gaussiano em uma imagem (processamento digital de imagens Rafael c. gonzalez)
image::./image/bordasderivadas.png[]

[.text-justify]
Como pode ser observado na <<bordasderivadas, figura 34>>, a primeira coluna representa a entrada com um aumento na intensidade do ruído gaussiano a cada linha. A coluna do meio mostra a resposta da primeira derivada e a segundo coluna refere-se à segunda derivada. Veja que ao aumentar a intensidade do ruído, torna-se inviável a utilização da segunda derivada, por isso, o processo prévio da filtragem é sempre importante.

[#s_exemplos3]
== 6. Exemplos do implementação de processamento digital de imagens para detecção de bordas utilizando openCV:

=== 4.2. Algoritmo de Canny e Pontilhismo
[.text-justify]
* O algoritmo de Canny para detecção de bordas (descontinuidades) em imagens é bem eficiente. Desenvolva um algoritmo capaz de gerar uma obra digital baseada no método de pintura "pontilhismo", utilizando o algoritmo de Canny para detectar as transições no gradiente da imagem, e gerando círculos menores, com raio igual a 1px, nessas regiões com bordas. Os pontos gerados nas demais regiões devem possuir raio variável, assim como o _threshold_ do canny.

[#cannyepontilhismo.cpp]
.cannyepontilhismo.cpp
[source,cannyepontilhismo.cpp]
----
#include <algorithm>
#include <cstdlib>
#include <ctime>
#include <fstream>
#include <iomanip>
#include <iostream>
#include <numeric>
#include <opencv2/opencv.hpp>
#include <vector>

#define STEP 1
#define JITTER 3
int RAIO = 3;

int top_slider = 10;
int top_slider_max = 200;

cv::Mat image, border, points;

char TrackbarName[50];

void on_trackbar_canny(int, void *)
{
    cv::Canny(image, border, top_slider, 3 * top_slider);
    cv::imshow("Canny", border);
}

void on_trackbar_pontilhismo(int, void *)
{
    std::vector<int> yrange;
    std::vector<int> xrange;

    int width, height;
    int x, y;

    std::srand(std::time(0));

    width = image.cols;
    height = image.rows;

    xrange.resize(height / STEP);
    yrange.resize(width / STEP);

    std::iota(xrange.begin(), xrange.end(), 0);
    std::iota(yrange.begin(), yrange.end(), 0);

    for (uint i = 0; i < xrange.size(); i++)
    {
        xrange[i] = xrange[i] * STEP + STEP / 2;
    }

    for (uint i = 0; i < yrange.size(); i++)
    {
        yrange[i] = yrange[i] * STEP + STEP / 2;
    }

    points = cv::Mat(height, width, CV_8UC3, cv::Scalar(255, 255, 255)); // Imagem colorida

    // Laço para gerar pontos de raio variável em posições aleatórias
    for (auto i : xrange)
    {
        std::random_shuffle(yrange.begin(), yrange.end());
        for (auto j : yrange)
        {
            // Define as posições para os pontos aleatórios
            x = i + std::rand() % (2 * JITTER) - JITTER + 1;
            y = j + std::rand() % (2 * JITTER) - JITTER + 1;

            // Vetor da cor do pixel em questão, da imagem original
            cv::Vec3b color = image.at<cv::Vec3b>(x, y);

            // Gera pontos com a cor do vetor color, de raio = RAIO (definido pelo usuário)
            cv::circle(points, cv::Point(y, x), RAIO, cv::Scalar(color[0], color[1], color[2]), cv::FILLED, cv::LINE_AA);
        }
    }

    // Laço para gerar pequenos pontos nas posições de bordas de Canny
    for (int i = 0; i < height; i++)
    {
        for (int j = 0; j < width; j++)
        {
            // Vetor da cor do pixel em questão, da imagem original
            cv::Vec3b color = image.at<cv::Vec3b>(i, j);

            // Verifica se a posição é uma borda na resposta de canny
            if (border.at<uchar>(i, j) == 255)
            {
                // Gera pontos com a cor do vetor color, de raio = 1
                cv::circle(points, cv::Point(j, i), 1, cv::Scalar(color[0], color[1], color[2]), cv::FILLED, cv::LINE_AA);
            }
        }
    }
    cv::imshow("Pontilhismo", points);
}

int main(int argc, char **argv)
{

    image = cv::imread(argv[1], cv::IMREAD_COLOR); // Carregar imagem em cores

    if (image.empty())
    {
        std::cout << "Could not open or find the image" << std::endl;
        return -1;
    }

    // Canny
    sprintf(TrackbarName, "Threshold inferior");

    cv::namedWindow("Canny", 1);
    cv::createTrackbar(TrackbarName, "Canny",
                       &top_slider,
                       top_slider_max,
                       on_trackbar_canny);

    on_trackbar_canny(top_slider, 0);

    // Pontilhismo
    sprintf(TrackbarName, "Raio");

    cv::namedWindow("Pontilhismo", 1);
    cv::createTrackbar(TrackbarName, "Pontilhismo",
                       &RAIO,
                       10,
                       on_trackbar_pontilhismo);

    on_trackbar_pontilhismo(RAIO, 0);

    cv::waitKey();
    cv::imwrite("pontos.jpg", points);
    cv::imwrite("cannyborders.png", border);
    return 0;
}
----

[.text-justify]
* Exemplo 13 (Continuação): Veja que o algoritmo acima gera duas _trackbartrackbar_ para alterar o valor do _threshold_ de canny e do raio dos pontos gerados aleatoriamente. Para que os pontos maiores não se sobreponham aos menores desenhados nas transições, o laço responsável por realizar o pontilhismo aleatório ocorre primeiro, permitindo que os pontos de raio 1 sejam pintados na imagem já finalizada com os pontos maiores. Além disso, a referência da coloração dos pixels é a imagem de entrada, não podendo ser alterada durante o processo. Portanto, a pintura é gravada em outra variável chamada "points". Veja na <<EntradaCannyePontilhismo, figura 35>>, a entrada do algoritmo.

[#EntradaCannyePontilhismo]
.Entrada para o algoritmo de Canny e Pontilhismo
image::./image/maceio.jpg[]

[.text-justify]
* Exemplo 13 (Continuação): A partir dessa entrada, foram obtidas as seguintes respostas variando as bordas de Canny e o raio dos pontos aleatórios:

[#saida1]
._Threshold_ = 0 e Raio = 0
image::./image/saida1.png[]

[#saida2]
._Threshold_ = 100 e Raio = 0
image::./image/saida2.png[]

[#saida3]
._Threshold_ = 100  e Raio = 2
image::./image/saida3.png[]

[#Pontos]
.Resposta da Arte de Pontilhismo
image::./image/pontos.jpg[]

[.text-justify]
* Exemplo 13 (Continuação): Note que com o raio aleatório igual a 0, temos apenas os pontos de raio igual a 1px que são gerados nas bordas de Canny definidas. Ao aumentar o tamanho do raio dos pontos aleatórios, os mesmos são desenhados nas regiões que não possuem bordas, ou seja, nas regiões escuras da resposta de Canny. O resultado da arte de pontilhismo pode ser visto na <<Pontos,figura 39>>.

[#s_Projeto]
== Projeto de PDI: Detecção de Caixas em uma Esteira

[.text-justify]
* A seguir será mostrado como foi realizado o projeto de Processamento Digital de Imagens, o qual diz respeito a uma problemática simples, mas que de forma semelhante, pode ter aplicações industriais. A ideia geral foi realizar a contagem de caixas que passam por um determinado ponto de uma esteira, levando em consideração apenas a diferença na itensidade do pixel da caixa, comparada com a intensidade do pixel da esteira. Para isso, foi utilizada uma esteira desenvolvida em uma turma do curso técnico em Mecatrônica do IFRN Campus Parnamirim. Veja a imagem da esteira na figura a seguir <<Esteira,esteira>>.

[#Esteira]
.Esteira (IFRN - Parnamirim)
image::./image/esteira.jpg[]

[.text-justify]
* As caixas foram feitas em origamis de formatos diferentes (<<Caixas, Caixas Origamis>>).

[#Caixas]
.Caixas Origamis
image::./image/caixas.jpeg[]

[.text-justify]
* A esteira utiliza um motor DC para o acionamento, logo a ideia da implementação foi posicionar a câmera em uma posição fixa acima da esteira, e ligar o motor com as caixas já posicionadas. À medida com que as caixas passam por uma determianada posição central da área de gravação, o algoritmo deve identificar que uma caixa está passando, e durante o vídeo deve ser contada a quantidade de caixa que passou. Como dito anteriormente, a presença de uma caixa na região central da gravação é identificada através do valor de intensidade do pixel no momento analisado, logo foi utilizado o sistema de cores HSI (_hue, saturation and intensity_) ou HSV (_hue, saturation and value_), utilizando-se da componente (itensidade). Veja abaixo os vídeos capturados:

.Vídeo de Entrada 1 - Esteira
video::M5s3YD7yq2c[youtube]

.Vídeo de Entrada 2 - Esteira
video::W2Syf5MaSps[youtube]

.Vídeo de Entrada 3 - Esteira
video::iccK1xhzv8s[youtube]

[#projeto.cpp]
.projeto.cpp
[source,projeto.cpp]
----
#include <iostream>
#include "opencv2/opencv.hpp"

int main(int argc, char **argv)
{

    cv::VideoCapture video("video3.mp4");

    if (!video.isOpened())
    {
        std::cout << "Erro ao abrir o vídeo." << std::endl;
        return -1;
    }

    // Definições da janela de exibição
    cv::namedWindow("Detecção de Caixas", cv::WINDOW_NORMAL);
    cv::resizeWindow("Detecção de Caixas", 800, 600);

    bool previousValue = false, pausado = false;
    ;
    int boxCount = 0;

    while (true)
    {
        if (!pausado)
        {
            cv::Mat frame;
            video >> frame;

            // Verifica se o vídeo terminou (frame == vazio)
            if (frame.empty())
                break;

            cv::Mat hsvFrame;
            // Conversão do sistema de cores RGB para o HSI (matriz, saturação e intensidade)
            cv::cvtColor(frame, hsvFrame, cv::COLOR_BGR2HSV);

            // Define o ponto central na imagem
            cv::Point center(frame.cols / 2, frame.rows / 2); // Ponto central

            // Obtém o Value (intensidade) vetorial no pixel do ponto central criado
            cv::Vec3b centerPixel = hsvFrame.at<cv::Vec3b>(center);

            // Captura o valor inteiro de intensidade
            int currentValueCenter = centerPixel[2];

            // Verifica se o frame anterior era da esteira
            if (currentValueCenter < 170)
            {
                previousValue = false;
            }

            // Verifica se houve mudança da esteira para a caixa
            if (currentValueCenter > 200 && !previousValue)
            {
                boxCount++;
                previousValue = true;
            }

            // Desenha um círculo ou marcador no centro da imagem
            // cv::circle(frame, center, 5, cv::Scalar(0, 0, 255), -1);
            cv::drawMarker(frame, center, cv::Scalar(0, 0, 255), cv::MARKER_CROSS, 20, 2);

            cv::putText(frame, "Numero de Caixas: " + std::to_string(boxCount), cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 0, 255), 2);
            cv::putText(frame, "previousValue: " + std::to_string(previousValue), cv::Point(10, 70), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 0, 255), 2);
            cv::putText(frame, "Valor de Intensidade (Center): " + std::to_string(currentValueCenter), cv::Point(10, 110), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 0, 255), 2);
            cv::imshow("Detecção de Caixas", frame);
        }
        if (cv::waitKey(1) == 'p' || cv::waitKey(1) == 'P') // Verifica se a tecla 'P' foi pressionada
            pausado = !pausado;                             // Inverte o estado do pausado
        if (cv::waitKey(1) == 27)
            break;
    }

    return 0;
}
----