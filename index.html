<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.20">
<meta name="author" content="E-mail">
<title>Albertho S. Costa - Engenheiro de Controle e Automação</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>Albertho S. Costa - Engenheiro de Controle e Automação</h1>
<div class="details">
<span id="author" class="author">E-mail</span><br>
<span id="email" class="email"><a href="mailto:albertho.costa.091@ufrn.edu.br">albertho.costa.091@ufrn.edu.br</a></span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Sumário</div>
<ul class="sectlevel1">
<li><a href="#_1_processamento_de_imagens_no_domínio_espacial">1. Processamento de Imagens no Domínio Espacial</a></li>
<li><a href="#_2_exemplos_do_implementação_de_processamento_digital_de_imagens_no_domínio_espacial_utilizando_opencv">2. Exemplos do implementação de processamento digital de imagens no domínio espacial utilizando openCV:</a>
<ul class="sectlevel2">
<li><a href="#_2_1_makefile">2.1. MakeFile</a></li>
<li><a href="#_2_2_helloworld">2.2. Helloworld</a></li>
<li><a href="#_2_3_pintando_pixels">2.3. Pintando Pixels</a></li>
<li><a href="#_2_4_negativo">2.4. Negativo</a></li>
<li><a href="#_2_5_trocando_quadrantes">2.5. Trocando Quadrantes</a></li>
<li><a href="#_2_6_png_versus_yml">2.6. PNG versus YML</a></li>
<li><a href="#_2_7_criptografia_por_esteganometria">2.7. Criptografia por Esteganometria</a></li>
<li><a href="#_2_8_algoritmo_de_floodfill">2.8. Algoritmo de Floodfill</a></li>
<li><a href="#_2_9_equalização_de_histogramas">2.9. Equalização de Histogramas</a></li>
<li><a href="#_2_10_filtragem_no_domínio_espacial">2.10. Filtragem no Domínio Espacial</a></li>
<li><a href="#_2_11_algoritmo_de_tiltshif">2.11. Algoritmo de Tiltshif</a></li>
</ul>
</li>
<li><a href="#s_ProcessamentodeImagensnoDomíniodafrequencia">3. Processamento de Imagens no Domínio da Frequência</a></li>
<li><a href="#s_exemplos2">4. Exemplos do implementação de processamento digital de imagens no domínio espacial utilizando openCV:</a>
<ul class="sectlevel2">
<li><a href="#s_11">4.1. Transformada Discreta de Fourier</a></li>
<li><a href="#s_12">4.2. Filtro Homomórfico</a></li>
</ul>
</li>
<li><a href="#s_Segmentaçãodeimagens">5. Segmentação de Imagens</a></li>
<li><a href="#s_exemplos3">6. Exemplos do implementação de processamento digital de imagens para detecção de bordas utilizando openCV:</a>
<ul class="sectlevel2">
<li><a href="#_4_2_algoritmo_de_canny_e_pontilhismo">4.2. Algoritmo de Canny e Pontilhismo</a></li>
</ul>
</li>
<li><a href="#s_Projeto">Projeto de PDI: Detecção de Caixas em uma Esteira</a></li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_1_processamento_de_imagens_no_domínio_espacial">1. Processamento de Imagens no Domínio Espacial</h2>
<div class="sectionbody">
<div class="paragraph text-justify">
<p>Ferramentas que buscam alterar uma determinada imagem de entrada, de maneira a deixá-la com aspectos mais realçados, suavizados (borramento), ou aspectos desejados de acordo com o processamento aplicado. Nesse caso, as operações são feitas diretamente no plano da imagem.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_2_exemplos_do_implementação_de_processamento_digital_de_imagens_no_domínio_espacial_utilizando_opencv">2. Exemplos do implementação de processamento digital de imagens no domínio espacial utilizando openCV:</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_2_1_makefile">2.1. MakeFile</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Arquivo Makefile que possui regras para compilar as dependências das bibliotecas openCV de forma automática.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Makefile</div>
<div class="content">
<pre class="highlight"><code class="language-Makefile" data-lang="Makefile">.SUFFIXES:
.SUFFIXES: .cpp

GCC = g++

.cpp:
	$(GCC) -Wall -Wunused -std=c++11 -O2 $&lt; -o $@ `pkg-config --cflags --libs opencv4`</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_2_helloworld">2.2. Helloworld</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 1: A primeira implementação é de um algoritmo "helloworld" que apresente uma imagem em tons de cinza via terminal, utilizando openCV na linguagem de programação C++. O algoritmo retorna a imagem do Biel na <a href="#biel">figura 1</a> vista a seguir.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">hello.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-hello.cpp" data-lang="hello.cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main(int argc, char** argv){
  cv::Mat image;
  image = cv::imread(argv[1],cv::IMREAD_GRAYSCALE);
  cv::imshow("image", image);
  cv::waitKey();
  return 0;
}</code></pre>
</div>
</div>
<div id="biel" class="imageblock text-center">
<div class="content">
<img src="./image/biel.png" alt="biel">
</div>
<div class="title">Figure 1. Biel</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_3_pintando_pixels">2.3. Pintando Pixels</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 2: O algoritmo a seguir abre a <a href="#bolhas">figura 2</a> (interpretando-a em escala de cinza), e a exibe em uma janela. Após isso, desenha um quadrado preto em uma região pré-estabelecida.
Em seguida, ele irá aguardar que o usuário pressione alguma tecla. Uma vez pressionada a tecla, o programa reabrirá o arquivo da imagem interpretando-a em escala de cores e passará a desenhar um quadrado vermelho na mesma região que foi pré-estabelecida.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">pixels.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-pixels.cpp" data-lang="pixels.cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;
int main(int, char**){
  cv::Mat image;
  cv::Vec3b val;
  image= cv::imread("bolhas.png",cv::IMREAD_GRAYSCALE);
  if(!image.data)
    std::cout &lt;&lt; "nao abriu bolhas.png" &lt;&lt; std::endl;
  cv::namedWindow("janela", cv::WINDOW_AUTOSIZE);
  for(int i=200;i&lt;210;i++){
    for(int j=10;j&lt;200;j++){
      image.at&lt;uchar&gt;(i,j)=0;
    }
  }
  cv::imshow("janela", image);
  cv::waitKey();
  image= cv::imread("bolhas.png",cv::IMREAD_COLOR);
  val[0] = 0;   //B
  val[1] = 0;   //G
  val[2] = 255; //R
  for(int i=200;i&lt;210;i++){
    for(int j=10;j&lt;200;j++){
      image.at&lt;cv::Vec3b&gt;(i,j)=val;
    }
  }
  cv::imshow("janela", image);
  cv::waitKey();
  return 0;
}</code></pre>
</div>
</div>
<div id="bolhas" class="imageblock">
<div class="content">
<img src="./image/bolhas.png" alt="bolhas">
</div>
<div class="title">Figure 2. Bolhas</div>
</div>
<div id="saidabolhas" class="imageblock">
<div class="content">
<img src="./image/saidabolhas.png" alt="saidabolhas">
</div>
<div class="title">Figure 3. pixels.cpp output</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_4_negativo">2.4. Negativo</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 3: O programa seguinte, <a href="#regionscpp">regions.cpp</a>, solicita ao usuário as coordenadas de dois pontos P1 e P2 localizados dentro dos limites do tamanho da imagem que lhe for fornecida (ver a <a href="#terminalregions">figura 4</a>). Entretanto, a região definida pelo retângulo de vértices opostos definidos pelos pontos P1 e P2 será exibida com o negativo da imagem na região correspondente. A resposta do algorimto pode ser vista na <a href="#regions">figura 5</a>.</p>
</li>
</ul>
</div>
<div id="regionscpp" class="listingblock">
<div class="title">regions.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-regions.cpp" data-lang="regions.cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main(int, char**){
  cv::Mat image;
  cv::Vec3b val;
  int xi,yi,xf,yf;

  //Carregando imagem:
  image = cv::imread("biel.png",cv::IMREAD_GRAYSCALE);
  if(!image.data)
    std::cout &lt;&lt; "nao abriu biel.png" &lt;&lt; std::endl;

  // Descobrindo o tamanho da imagem:
  cv::Size size = image.size();
  std::cout &lt;&lt; "Considerando que a imagem tem as seguintes dimensões:" &lt;&lt; std::endl;

  // Imprime o tamanho em pixels:
  std::cout &lt;&lt; "Largura: " &lt;&lt; size.width &lt;&lt; " pixels" &lt;&lt; std::endl;
  std::cout &lt;&lt; "Altura: " &lt;&lt; size.height &lt;&lt; " pixels" &lt;&lt; std::endl;

  // Recebendo valores:
  std::cout &lt;&lt; "Defina dois pontos (x,y) opostos de um retângulo que contemple essa dimensão da imagem:" &lt;&lt; std::endl;
  std::cout &lt;&lt;"Ponto inicial (X):";
  std::cin &gt;&gt; xi;
  std::cout &lt;&lt;"Ponto inicial (Y):";
  std::cin &gt;&gt; yi;
  std::cout &lt;&lt;"Ponto final (X):";
  std::cin &gt;&gt; xf;
  std::cout &lt;&lt;"Ponto final (Y):";
  std::cin &gt;&gt; yf;

  cv::imshow("janela", image);
  cv::waitKey();

  image = cv::imread("biel.png",cv::IMREAD_GRAYSCALE);
  cv::namedWindow("janela", cv::WINDOW_AUTOSIZE);

  for(int i=xi;i&lt;=xf;i++){
    for(int j=yi;j&lt;=yf;j++){
        image.at&lt;uchar&gt;(i,j) = 255 - (image.at&lt;uchar&gt;(i,j));
    }
  }

  cv::imshow("janela", image);
  cv::waitKey();

  return 0;
}</code></pre>
</div>
</div>
<div id="terminalregions" class="imageblock">
<div class="content">
<img src="./image/terminalregions.png" alt="terminalregions">
</div>
<div class="title">Figure 4. Terminal: regions.cpp</div>
</div>
<div id="regions" class="imageblock">
<div class="content">
<img src="./image/saidaregions.png" alt="saidaregions">
</div>
<div class="title">Figure 5. regions.cpp Output</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_5_trocando_quadrantes">2.5. Trocando Quadrantes</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 4: O quarto exemplo faz a troca de quadrantes diagonal na imagem. Esse procedimento é uma etapa importante em processamento de imagens no domínio da frequência, e será implementado novamente mais na frente. É explorado no algoritmo <a href="#trocarregioes">trocarregioes.cpp</a> o uso da classe Mat e seus construtores para criar as regiões que serão trocadas.</p>
</li>
</ul>
</div>
<div id="trocarregioes" class="listingblock">
<div class="title">trocarregioes.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-trocaregioes.cpp" data-lang="trocaregioes.cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main(int, char **)
{
    cv::Mat image;
    cv::Vec3b val;

    // Carregando imagem:
    image = cv::imread("biel.png", cv::IMREAD_GRAYSCALE);
    if (!image.data)
        std::cout &lt;&lt; "nao abriu biel.png" &lt;&lt; std::endl;

    // Descobrindo o tamanho da imagem:
    cv::Size size = image.size();
    std::cout &lt;&lt; "Considerando que a imagem tem as seguintes dimensões:" &lt;&lt; std::endl;

    // Imprime o tamanho em pixels:
    std::cout &lt;&lt; "Largura: " &lt;&lt; size.width &lt;&lt; " pixels" &lt;&lt; std::endl;
    std::cout &lt;&lt; "Altura: " &lt;&lt; size.height &lt;&lt; " pixels" &lt;&lt; std::endl;
    cv::imshow("janela 1", image);
    cv::waitKey();

    // Definindo os 4 quadrantes com submatrizes na classe "Mat":
    int largura = size.width / 2;
    int altura = size.height / 2;
    cv::Mat quadrante1 = image(cv::Rect(0, 0, largura, altura));
    cv::Mat quadrante2 = image(cv::Rect(largura, 0, largura, altura));
    cv::Mat quadrante3 = image(cv::Rect(0, altura, largura, altura));
    cv::Mat quadrante4 = image(cv::Rect(largura, altura, largura, altura));

    // Usando o método "hconcat" da classe "Mat" para concatentar os quadrantes opostos
    // horizontalmente em duas linhas, e o método "vconcat" para concatenar as linhas com
    // os quadrantes já reorganizados:

    cv::Mat linha1, linha2, imagemFinal;
    cv::hconcat(quadrante4, quadrante3, linha1);
    cv::hconcat(quadrante2, quadrante1, linha2);
    cv::vconcat(linha1, linha2, imagemFinal);

    imwrite("saidaquadrantes.png", imagemFinal);

    cv::imshow("janela 2", imagemFinal);
    cv::waitKey();

    return 0;
}</code></pre>
</div>
</div>
<div class="paragraph text-justify">
<p>A imagem que foi usada como entrada para o algoritmo é a do <a href="#biel">Biel</a>. A saída mostra os quadrantes diagonais trocados. Veja a <a href="#saidaquadrantes">figura 6</a>.</p>
</div>
<div id="saidaquadrantes" class="imageblock">
<div class="content">
<img src="./image/saidaquadrantes.png" alt="saidaquadrantes">
</div>
<div class="title">Figure 6. trocaregioes.cpp Output</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_6_png_versus_yml">2.6. PNG versus YML</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 5: O programa a seguir gera uma imagem de dimensões 256x256 pixels contendo uma senóide de 4 períodos com amplitude de 127 desenhada na horizontal. Grava a imagem no formato PNG que possui valores inteiros, e no formato YML com valores em pontos flutuantes. Por último é feita uma comparação entre os arquivos gerados, extraindo uma linha de cada imagem gravada e comparando a diferença entre elas. É possível observar no gráfico da <a href="#ymlxpng">figura 8</a> gerado que a diferença entre as duas imagens é pequena, considerando que os valores são menores que 1, e os pixeis representam 256 possíveis tons de cinza. Note que haveria uma mudança significativa na visualização da imagem PNG gerada, se o arredondamento resultante da imagem YML mudasse mais de 5 tons de pixeis, o que não ocorre nessa situação. O algoritmo gera também dois arquivos no formato TXT, e o gráfico foi gerado no excel.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">filestorage.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-filestorage.cpp" data-lang="filestorage.cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;sstream&gt;
#include &lt;string&gt;
#include &lt;fstream&gt;
int SIDE = 256;
int PERIODOS = 8;

int main(int argc, char **argv)
{
  std::stringstream ss_img, ss_yml;
  cv::Mat image;
  ss_yml &lt;&lt; "senoide-" &lt;&lt; SIDE &lt;&lt; ".yml";
  image = cv::Mat::zeros(SIDE, SIDE, CV_32FC1);
  cv::FileStorage fs(ss_yml.str(), cv::FileStorage::WRITE);

  for (int i = 0; i &lt; SIDE; i++)
  {
    for (int j = 0; j &lt; SIDE; j++)
    {
      image.at&lt;float&gt;(i, j) = 127 * sin(2 * M_PI * PERIODOS * j / SIDE) + 128;
    }
  }

  // Criando um .txt referente à imagem .yml
  std::ofstream outFileyml("imageyml.txt");
  if (!outFileyml.is_open())
  {
    std::cout &lt;&lt; "Erro ao criar o arquivo de saída." &lt;&lt; std::endl;
    return -1;
  }
  for (int i = 0; i &lt; image.rows; i++)
  {
    for (int j = 0; j &lt; image.cols; j++)
    {
      float pixelValues = image.at&lt;float&gt;(i, j);
      outFileyml &lt;&lt; pixelValues &lt;&lt; " ";
    }
    outFileyml &lt;&lt; std::endl;
  }
  outFileyml.close();
  fs &lt;&lt; "mat" &lt;&lt; image;
  fs.release();
  cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
  image.convertTo(image, CV_8U);
  ss_img &lt;&lt; "senoide-" &lt;&lt; SIDE &lt;&lt; ".png";
  cv::imwrite(ss_img.str(), image);
  fs.open(ss_yml.str(), cv::FileStorage::READ);
  fs["mat"] &gt;&gt; image;
  cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
  image.convertTo(image, CV_8U);

  // Criando um .txt referente à imagem .png
  std::ofstream outFilepng("imagePNG.txt");
  if (!outFilepng.is_open())
  {
    std::cout &lt;&lt; "Erro ao criar o arquivo de saída." &lt;&lt; std::endl;
    return -1;
  }
  for (int i = 0; i &lt; image.rows; i++)
  {
    for (int j = 0; j &lt; image.cols; j++)
    {
      int pixelValue = image.at&lt;uchar&gt;(i, j);
      outFilepng &lt;&lt; pixelValue &lt;&lt; " ";
    }
    outFilepng &lt;&lt; std::endl;
  }
  outFilepng.close();
  cv::imshow("image", image);
  cv::waitKey();

  return 0;
}</code></pre>
</div>
</div>
<div id="senoide" class="imageblock">
<div class="content">
<img src="./image/senoidePNG-256.png" alt="senoidePNG 256">
</div>
<div class="title">Figure 7. Senoide Gerada</div>
</div>
<div id="ymlxpng" class="imageblock">
<div class="content">
<img src="./image/pngxyml.png" alt="pngxyml">
</div>
<div class="title">Figure 8. Gráfico da Diferença</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_7_criptografia_por_esteganometria">2.7. Criptografia por Esteganometria</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 6: O algoritmo a seguir realiza uma descriptografia de uma imagem que passou por um processo de esteganografia. Lembre-se que os bits menos significativos dos pixels da imagem fornecida deverão compor os bits mais significativos dos pixels da imagem recuperada. O programa recebe como parâmetros de linha de comando o nome da imagem resultante da esteganografia (<a href="#cripto">Figura 9</a>).</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">descriptesteganometria.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-descriptesteganometria.cpp" data-lang="descriptesteganometria.cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main(int argc, char**argv) {
  cv::Mat imagemPortadora, imagemFinal;
  cv::Vec3b valPortadora;
  int nbits = 3;
  imagemPortadora = cv::imread(argv[1], cv::IMREAD_COLOR);
  std::string imagemDecodificada;
  std::cout &lt;&lt; "Digite o nome que queres para a imagem resultante da decodificação (.png):" &lt;&lt; std::endl;
  std::cin &gt;&gt; imagemDecodificada;
  if (imagemPortadora.empty()) {
    std::cout &lt;&lt; "imagem nao carregou corretamente" &lt;&lt; std::endl;
    return (-1);
  }

  imagemFinal = imagemPortadora.clone();
  for (int i = 0; i &lt; imagemPortadora.rows; i++) {
    for (int j = 0; j &lt; imagemPortadora.cols; j++) {
      valPortadora = imagemPortadora.at&lt;cv::Vec3b&gt;(i, j);
      valPortadora[0] = valPortadora[0] &lt;&lt; (8-nbits); // Desloca 5 vezes à esquerda os bits da imagemPortadora[0]
      valPortadora[1] = valPortadora[1] &lt;&lt; (8-nbits); // Desloca 5 vezes à esquerda os bits da imagemPortadora[1]
      valPortadora[2] = valPortadora[2] &lt;&lt; (8-nbits); // Desloca 5 vezes à esquerda os bits da imagemPortadora[2]
      imagemFinal.at&lt;cv::Vec3b&gt;(i, j) = valPortadora;
      // Ex: [11111555] -&gt; [11115550] -&gt; [11155500] ... -&gt; [55500000]
      // Dessa forma, os 3 bits escondidos nos 3 menos significativos
      // se tornam os 3 mais significativos
    }
  }

  imwrite(imagemDecodificada, imagemFinal);
  cv::imshow("image", imagemPortadora);
  cv::waitKey();
  cv::imshow("image", imagemFinal);
  cv::waitKey();

  return 0;
}</code></pre>
</div>
</div>
<div id="cripto" class="imageblock">
<div class="content">
<img src="./image/desafio-esteganografia.png" alt="desafio esteganografia">
</div>
<div class="title">Figure 9. Imagem criptografada por esteganometria</div>
</div>
<div id="steg" class="imageblock">
<div class="content">
<img src="./image/estegsaida.png" alt="estegsaida">
</div>
<div class="title">Figure 10. Imagem Descriptografada</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_8_algoritmo_de_floodfill">2.8. Algoritmo de Floodfill</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 7: Uma implementação interessante em processamento digital de imagens é o cálculo de objetos presentes em uma determinada cena. A identificação das bolhas na <a href="#bolhas">figura 2</a> (regiões brancas) pode variar de acordo com a consideração que é feita para os objetos (bolhas). Dessa forma, o algoritmo a seguir busca inicialmente excluir os objetos na borda da imagem, após isso ele identifica os objetos com "buracos" (bolhas com regiões pretas dentro), e retorna no terminal a quantidade de bolhas nas bordas, de buracos e das bolhas resultantes na imagem. Para isso, foi utilizado o algoritmo floodfill.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">bolhascombolhas.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-bolhascombolhas.cpp" data-lang="bolhascombolhas.cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;
using namespace cv;

int main(int argc, char **argv)
{
    cv::Mat image;
    int width, height;
    int nobjects, edgeobjects, holeobjects;
    cv::Point p;
    image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);
    if (!image.data)
    {
        std::cout &lt;&lt; "imagem nao carregou corretamente\n";
        return (-1);
    }
    cv::imshow("image", image);
    cv::waitKey();
    width = image.cols;
    height = image.rows;
    std::cout &lt;&lt; width &lt;&lt; "x" &lt;&lt; height &lt;&lt; std::endl;
    p.x = 0;
    p.y = 0;

    // busca objetos presentes nas bordas e pinta de preto
    edgeobjects = 0;
    for (int i = 0; i &lt; height; i++)
    {
        for (int j = 0; j &lt; width; j++)
        {
            if (i == 0 || i == (height - 1) || j == 0 || j == (width - 1))
            {
                if (image.at&lt;uchar&gt;(i, j) == 255)
                {
                    // Achou um objeto (bolha) na borda
                    // Para o floodfill as coordenadas
                    // x e y são trocadas.
                    p.x = j;
                    p.y = i;
                    edgeobjects++;
                    cv::floodFill(image, p, 0);
                }
            }
        }
    }
    cv::imshow("image", image);
    cv::imwrite("sembordas.png", image);
    cv::waitKey();

    // busca objetos com bolhas internas
    // Muda a cor do fundo preto para o tom
    // de cinza 150 (uma vez que ele começa a
    // percorrer pela borda e como as bolhas
    // das bordas sumiram, o primeiro ponto
    // preto encontrado será o fundo)

    p.x = 0;
    p.y = 0;
    cv::floodFill(image, p, 150);
    holeobjects = 0;
    cv::imshow("image", image);
    cv::imwrite("mudacor.png", image);
    cv::waitKey();
    for (int i = 0; i &lt; height; i++)
    {
        for (int j = 0; j &lt; width; j++)
        {
            if (image.at&lt;uchar&gt;(i, j) == 0)
            {
                // Procura o próximo ponto preto
                // que será, necessariamente, uma
                // bolha interna, uma vez que o
                // fundo não é mais preto. Transforma
                // essa região em branco, eliminando
                // a bolha interna
                p.x = j;
                p.y = i;
                holeobjects++;
                cv::floodFill(image, p, 255);
            }
        }
    }
    cv::imshow("image", image);
    cv::imwrite("semburacos.png", image);
    cv::waitKey();

    // Muda a cor do fundo do tom de cinza 150 para
    // preto (0)
    p.x = 0;
    p.y = 0;
    cv::floodFill(image, p, 0);
    cv::imshow("image", image);
    cv::imwrite("voltacor.png", image);
    cv::waitKey();

    // busca objetos presentes
    nobjects = 0;
    for (int i = 0; i &lt; height; i++)
    {
        for (int j = 0; j &lt; width; j++)
        {
            if (image.at&lt;uchar&gt;(i, j) == 255)
            {
                // achou um objeto
                nobjects++;
                // para o floodfill as coordenadas
                // x e y são trocadas.
                p.x = j;
                p.y = i;
                // preenche o objeto com o contador
                cv::floodFill(image, p, nobjects);
            }
        }
    }
    std::cout &lt;&lt; "a figura tinha " &lt;&lt; edgeobjects &lt;&lt; " bolhas nas bordas\n";
    std::cout &lt;&lt; "a figura tinha " &lt;&lt; holeobjects &lt;&lt; " buracos\n";
    std::cout &lt;&lt; "a figura tem " &lt;&lt; nobjects &lt;&lt; " bolhas\n";
    cv::imshow("image", image);
    cv::imwrite("labeling.png", image);
    cv::waitKey();

    return 0;
}</code></pre>
</div>
</div>
<div id="passo1" class="imageblock">
<div class="content">
<img src="./image/sembordas.png" alt="sembordas">
</div>
<div class="title">Figure 11. Passo 01</div>
</div>
<div id="passo2" class="imageblock">
<div class="content">
<img src="./image/mudacor.png" alt="mudacor">
</div>
<div class="title">Figure 12. Passo 02</div>
</div>
<div id="passo3" class="imageblock">
<div class="content">
<img src="./image/semburacos.png" alt="semburacos">
</div>
<div class="title">Figure 13. Passo 03</div>
</div>
<div id="passo4" class="imageblock">
<div class="content">
<img src="./image/voltacor.png" alt="voltacor">
</div>
<div class="title">Figure 14. Passo 04</div>
</div>
<div id="passo5" class="imageblock">
<div class="content">
<img src="./image/labeling.png" alt="labeling">
</div>
<div class="title">Figure 15. Passo 05</div>
</div>
<div id="terminalfloodfill" class="imageblock">
<div class="content">
<img src="./image/terminaloutput.png" alt="terminaloutput">
</div>
<div class="title">Figure 16. terminal Output</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_9_equalização_de_histogramas">2.9. Equalização de Histogramas</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 8: A próxima implementação utiliza dos conceitos de equalização de histogramas para melhorar a distribuição de tons de cinza em uma determinada imagem. O algoritmo retorna continuamente duas janelas de visualização da webcam do computador, uma é relativa à imagem original (<a href="#image">figura 17</a>) em tons de cinza, e a outra refere-se à essa imagem equalizada (<a href="#imagequalized">figura 18</a>). Ao pressionar "ESC" o programa finaliza e retorna a captura das imagens no momento ligeiramente antes de pressionar a tecla.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">equalize.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-equalize.cpp" data-lang="equalize.cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main(int argc, char** argv){
  cv::Mat image,grayFrame,equalizedImg;
  int width, height;
  cv::VideoCapture cap;
  std::vector&lt;cv::Mat&gt; planes;
  cv::Mat hist;
  int nbins = 64;
  float range[] = {0, 255};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
  int key;

  cap.open(0);

  if(!cap.isOpened()){
    std::cout &lt;&lt; "cameras indisponiveis";
    return -1;
  }

  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

  std::cout &lt;&lt; "largura = " &lt;&lt; width &lt;&lt; std::endl;
  std::cout &lt;&lt; "altura  = " &lt;&lt; height &lt;&lt; std::endl;

  int histw = nbins, histh = nbins/2;
  cv::Mat histImg(histh, histw, CV_8UC3, cv::Scalar(0));

  while(1){
    cap &gt;&gt; image;

    cv::Mat grayFrame;
    cv::cvtColor(image, grayFrame, cv::COLOR_BGR2GRAY);

    //cv::split (grayFrame, planes);
    cv::calcHist(&amp;grayFrame, 1, 0, cv::Mat(), hist, 1,
                 &amp;nbins, &amp;histrange,
                 uniform, acummulate);

    cv::normalize(hist, hist, 0, histImg.rows, cv::NORM_MINMAX, -1, cv::Mat());

    // Equalizar o histograma
    cv::Mat equalizedImg;
    cv::equalizeHist(grayFrame, equalizedImg);

    histImg.setTo(cv::Scalar(0));

    for(int i=0; i&lt;nbins; i++){
      cv::line(histImg,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(hist.at&lt;float&gt;(i))),
               cv::Scalar(0, 0, 255), 1, 8, 0);
    }
    cv::imshow("image", grayFrame);
    cv::imshow("image equalized", equalizedImg);
    key = cv::waitKey(30);
    if(key == 27)
    {
      cv::imwrite("image.png", grayFrame);
      cv::imwrite("imagequalized.png", equalizedImg);
      break;
    }
  }
  return 0;
}</code></pre>
</div>
</div>
<div id="image" class="imageblock">
<div class="content">
<img src="./image/image.png" alt="image">
</div>
<div class="title">Figure 17. Imagem Original</div>
</div>
<div id="imagequalized" class="imageblock">
<div class="content">
<img src="./image/imagequalized.png" alt="imagequalized">
</div>
<div class="title">Figure 18. Imagem Equalizada</div>
</div>
<div class="paragraph text-justify">
<p>Como pode ser observado, a equalização revela detalhes antes escondidos pela baixa iluminação, como a mão, a barba e alguns contornos.</p>
</div>
</div>
<div class="sect2">
<h3 id="_2_10_filtragem_no_domínio_espacial">2.10. Filtragem no Domínio Espacial</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 9: A filtragem no domínio espacial é uma ferramenta que busca alterar uma determinada imagem de entrada, de maneira a deixá-la com aspectos mais realçados, suavizados (borramento), ou aspectos desejados de acordo com o filtro utilizado. Nesse caso, as operações são feitas diretamente no plano da imagem. É possível realizar a filtragem através da convolução bidimensional de uma máscara (matriz de tamanho ímpar) com a matriz que representa a imagem a ser filtrada. A fórmula da convolução pode ser observada na <a href="#convolucao">figura 19</a>.</p>
</li>
</ul>
</div>
<div id="convolucao" class="imageblock">
<div class="content">
<img src="./image/convolucao.png" alt="convolucao">
</div>
<div class="title">Figure 19. Convolução bidimensional</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 9 (Continuação): Baseado nisso, o algoritmo a seguir foi desenvolvido para realizar o filtro laplaciano do gaussiano, onde a princípio aplica-se a máscara gaussiana na imagem de entrada, e em seguida aplica a máscara laplaciana. Além desse filtro, também é possível aplicar uma série de filtros diferentes: filtro da média; gaussiano; sobel horizontal; sobel vertical; sobel +45°; -45°; laplaciano e boost. O usuário determina qual filtro especificamente deseja aplicar à imagem de entrada via terminal, de acordo com a letra digitada (ver switch case no algoritmo <a href="#lapgaus">lapgauss.cpp</a>).</p>
</li>
</ul>
</div>
<div id="lapgaus" class="listingblock">
<div class="title">lapgauss.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-lapgauss.cpp" data-lang="lapgauss.cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main(int, char **)
{
    cv::Mat image;

    //image = cv::imread("imgsalepimenta.png", cv::IMREAD_GRAYSCALE);
    image = cv::imread("sobel.png", cv::IMREAD_GRAYSCALE);


    if (!image.data)
        std::cout &lt;&lt; "nao abriu imgsalepimenta.png" &lt;&lt; std::endl;

    cv::imshow("Original", image);

    float media[] = {0.1111, 0.1111, 0.1111, 0.1111, 0.1111,
                     0.1111, 0.1111, 0.1111, 0.1111};
    float gauss[] = {0.0625, 0.125, 0.0625, 0.125, 0.25,
                     0.125, 0.0625, 0.125, 0.0625};
    float vertical [] = {-1, 0, 1, -2, 0, 2, -1, 0, 1};     // Máscara de Sobel vertical
    float horizontal [] = {-1, -2, -1, 0, 0, 0, 1, 2, 1};   // Máscara de Sobel horizontal
    float mais45 [] = {0, 1, 2, -1, 0, 1, -2, -1, 0};       // Máscara de Sobel +45°
    float menos45 [] = {-2, -1, 0, -1, 0, 1, 0, 1, 2};      // Máscara de Sobel -45°
    float laplacian[] = {0, -1, 0, -1, 4, -1, 0, -1, 0};
    float boost[] = {0, -1, 0, -1, 5.2, -1, 0, -1, 0};      // Máscara de nitidez

    cv::Mat image32f, imageFiltered, secondFilteredimage;
    cv::Mat mask(3, 3, CV_32F);
    cv::Mat result;
    int absolut, laplgauss = 0;
    char key;

    mask = cv::Mat(3, 3, CV_32F, media);
    absolut = 1; // calcs abs of the image

    // Loop para o programa rodar até que ESC seja pressionada
    while(key != 27){

    key = (char)cv::waitKey();
    switch (key)
    {
    case 'a':
        absolut = !absolut;
        laplgauss = 0;
        break;
    case 'm':
        mask = cv::Mat(3, 3, CV_32F, media);
        laplgauss = 0;
        break;
    case 'g':
        mask = cv::Mat(3, 3, CV_32F, gauss);
        laplgauss = 0;
        break;
    case 'h':
        mask = cv::Mat(3, 3, CV_32F, horizontal);
        laplgauss = 0;
        break;
    case 'v':
        mask = cv::Mat(3, 3, CV_32F, vertical);
        laplgauss = 0;
        break;
    case 'j':
        mask = cv::Mat(3, 3, CV_32F, mais45);
        laplgauss = 0;
        break;
    case 'k':
        mask = cv::Mat(3, 3, CV_32F, menos45);
        laplgauss = 0;
        break;
    case 'l':
        mask = cv::Mat(3, 3, CV_32F, laplacian);
        laplgauss = 0;
        break;
    case 'b':
        mask = cv::Mat(3, 3, CV_32F, boost);
        laplgauss = 0;
        break;
    case 'p':
        // Opção para o filtro LoG (Laplaciano do Gaussiano)
        laplgauss = 1;
        break;
    default:
        break;
    }

    // Caso a seleção seja Laplaciano do Gaussiano
    if (laplgauss == 1)
    {
        image.convertTo(image32f, CV_32F);

        // Aplicando o filtro gaussiano
        mask = cv::Mat(3, 3, CV_32F, gauss);
        cv::filter2D(image32f, imageFiltered, image32f.depth(),
                     mask,
                     cv::Point(1, 1), 0);
        // Aplicando o filtro laplaciano
        mask = cv::Mat(3, 3, CV_32F, laplacian);
        cv::filter2D(imageFiltered, secondFilteredimage, image32f.depth(),
                     mask,
                     cv::Point(1, 1), 0);

        if (absolut)
        {
            secondFilteredimage = cv::abs(secondFilteredimage);
        }

        secondFilteredimage.convertTo(result, CV_8U);
    }
    else if (laplgauss == 0)
    {
        image.convertTo(image32f, CV_32F);

        cv::filter2D(image32f, imageFiltered, image32f.depth(),
                     mask,
                     cv::Point(1, 1), 0);
        if (absolut)
        {
            imageFiltered = cv::abs(imageFiltered);
        }

        imageFiltered.convertTo(result, CV_8U);
    }

    cv::imshow("Filtrado", result);
    }
    //cv::waitKey();
    return 0;
}</code></pre>
</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 9 (Continuação): A imagem de entrada <a href="#salepimenta">figura 20</a>, retirada do livro de Processamento Digital de Imagens de Rafael C. Gonzalez, foi utilizada para avaliar os efeitos de suavização do ruido na aplicação dos filtros mostrados acima. Vale salientar que o filtro ideal para esse tipo de ruido é o filtro da mediana.</p>
</li>
</ul>
</div>
<div id="salepimenta" class="imageblock">
<div class="content">
<img src="./image/imgsalepimenta.png" alt="imgsalepimenta">
</div>
<div class="title">Figure 20. Ruído Sal e Pimenta (processamento digital de imagens - Rafael c. gonzalez)</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 9 (Continuação): As respostas da media, laplaciano, gaussiano e laplaciano do gaussiano são vistas, respectivamente, nas seguintes figuras: <a href="#media">figura 21</a>, <a href="#gaussiano">figura 22</a>, <a href="#laplaciano">figura 23</a>, <a href="#log">figura 24</a>.</p>
</li>
</ul>
</div>
<div id="media" class="imageblock">
<div class="content">
<img src="./image/media.png" alt="media">
</div>
<div class="title">Figure 21. Filtragem com máscara da média</div>
</div>
<div id="gaussiano" class="imageblock">
<div class="content">
<img src="./image/gaussiano.png" alt="gaussiano">
</div>
<div class="title">Figure 22. Filtragem com máscara gaussiana</div>
</div>
<div id="laplaciano" class="imageblock">
<div class="content">
<img src="./image/laplaciano.png" alt="laplaciano">
</div>
<div class="title">Figure 23. Filtragem com máscara laplaciana</div>
</div>
<div id="log" class="imageblock">
<div class="content">
<img src="./image/log.png" alt="log">
</div>
<div class="title">Figure 24. Filtragem com máscara laplaciano do gaussiano</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 9 (Continuação): Note que o filtro laplaciano do gaussiano apresenta detalhes de contornos na imagem, mas com uma quantidade de ruído bem menor que o filtro somente laplaciano. Isso ocorre pela suavização feita pelo filtro gaussiano antes da aplicação do laplaciano. Além disso, é notório o borramento causado pelos filtros da média e gaussiano. Para reduzir a suavização ocasionada pelo filtro da média, é possível realizar a média ponderada, definindo na máscara pesos maiores para a sua região central (veja a <a href="#mascaramedia">figura 25</a> retirada do livro de Rafael C. Gonzalez. A letra "a" é a máscara da média e "b" da média ponderada).</p>
</li>
</ul>
</div>
<div id="mascaramedia" class="imageblock">
<div class="content">
<img src="./image/filtrodamedia.png" alt="filtrodamedia">
</div>
<div class="title">Figure 25. Máscaras da média aritmética (a) e média ponderada (b) (processamento digital de imagens - Rafael c. gonzalez)</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_11_algoritmo_de_tiltshif">2.11. Algoritmo de Tiltshif</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 10: Tiltshift</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="s_ProcessamentodeImagensnoDomíniodafrequencia">3. Processamento de Imagens no Domínio da Frequência</h2>
<div class="sectionbody">
<div class="paragraph text-justify">
<p>Antes de inciar o tópico de Processamento de Imagens no Domínio da Frequência, é interessante comentar sobre a importância da transformada discreta de Fourier (DFT) nessas aplicações, mais especificamente, a transformada discreta de Fourier de duas dimensões (<a href="#DFT">figura 26</a>).</p>
</div>
<div id="DFT" class="imageblock">
<div class="content">
<img src="./image/DFT.png" alt="DFT">
</div>
<div class="title">Figure 26. Transformada Discreta de Fourier 2D (processamento digital de imagens - Rafael c. gonzalez)</div>
</div>
<div id="IDFT" class="imageblock">
<div class="content">
<img src="./image/IDFT.png" alt="IDFT">
</div>
<div class="title">Figure 27. Transformada Discreta de Fourier 2D Inversa (processamento digital de imagens - Rafael c. gonzalez)</div>
</div>
<div class="paragraph text-justify">
<p>A transformada discreta de Fourier bidimensional é muito importante para o processamento de imagens, pois permite discretizar um sinal contínuo em funções senoidais ponderadas. No caso das imagens digitais, a DFT permite visualizar aspectos periódicos através de sua resposta em magnitude (<a href="#espectromag">figura 28</a>), sendo possível assim, elimitar ruidos com características periódicas. Algumas características da transformada discreta de Fourier são levadas em consideração para a sua implementação em algoritmos de processamento digital de imagens. Por exemplo, considerando que a transformada e sua inversa são infinitamentes periódicas, é possível centralizar um período completo da transformada  deslocando os dados para o centro da imagem. Uma vez que as componentes de altas frequência da matriz da imagem encontram-se nas suas extremidades, alterar os quadrantes da matriz (de forma semelhante ao deslocamento visto na <a href="#saidaquadrantes">figura 6</a>) permite uma fácil visualização e filtragem dessas componentes, as quais podem representar os ruídos periódicos presentes.</p>
</div>
<div id="espectromag" class="imageblock">
<div class="content">
<img src="./image/espectrodefourier(magnitude).png" alt="espectrodefourier(magnitude)">
</div>
<div class="title">Figure 28. Espectro em Magnitude (processamento digital de imagens - Rafael c. gonzalez)</div>
</div>
<div class="paragraph text-justify">
<p>Além da resposta em magnitude (espectro em magnitude), a transformada também pode retornar o Ângulo de Fase (espectro em fase) (<a href="#angulodefase">figura 29</a>). Esse pode ser muito útil em algoritmos de rastreamento de contornos, que serão vistos posteriormente.</p>
</div>
<div id="angulodefase" class="imageblock">
<div class="content">
<img src="./image/angulodefase(magnitude).png" alt="angulodefase(magnitude)">
</div>
<div class="title">Figure 29. Ângulo de Fase (processamento digital de imagens - Rafael c. gonzalez)</div>
</div>
<div class="paragraph text-justify">
<p>Levando em consideração os conceitos sobre a DFT, para realizar a filtragem de imagens no domínio da frequência e retornar a imagem no domínio de visualização, basta calcular a inversa da DFT com a máscara utilizada (ver <a href="#filtragemfreq">figura 30</a>).</p>
</div>
<div id="filtragemfreq" class="imageblock">
<div class="content">
<img src="./image/filtragemFreqEq.png" alt="filtragemFreqEq">
</div>
<div class="title">Figure 30. Filtragem no Domínio da Frequência (processamento digital de imagens - Rafael c. gonzalez)</div>
</div>
<div class="paragraph text-justify">
<p>Entre os tipos de filtros utilizados, podem-se citar os filtros low-pass e high-pass. Ao atenuar altas frequências (low-pass) propõe uma diminuição visual dos pontos de grandes transições de intensidades em uma imagem, deixando-a borrada. Já, ao filtrar baixas frequências (high-pass) ocorre o realce dos pontos de grandes transições de intensidades, mas deixa a imagem resultante com um menor contraste.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="s_exemplos2">4. Exemplos do implementação de processamento digital de imagens no domínio espacial utilizando openCV:</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="s_11">4.1. Transformada Discreta de Fourier</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 11: O algoritmo a seguir, utiliza a <a href="#senoide">figura 7</a> da senoide, e calcula os seus espectros em magnitude e em fase.</p>
</li>
</ul>
</div>
<div id="dftimage" class="listingblock cpp">
<div class="title">dftimage.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-dftimage.cpp" data-lang="dftimage.cpp">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;opencv2/opencv.hpp&gt;

void swapQuadrants(cv::Mat &amp;image)
{
  cv::Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para o maior
  // tamanho par possivel (-2 = 1111...1110)
  image = image(cv::Rect(0, 0, image.cols &amp; -2, image.rows &amp; -2));

  int centerX = image.cols / 2;
  int centerY = image.rows / 2;

  // rearranja os quadrantes da transformada de Fourier de forma que
  // a origem fique no centro da imagem
  // A B   -&gt;  D C
  // C D       B A
  A = image(cv::Rect(0, 0, centerX, centerY));
  B = image(cv::Rect(centerX, 0, centerX, centerY));
  C = image(cv::Rect(0, centerY, centerX, centerY));
  D = image(cv::Rect(centerX, centerY, centerX, centerY));

  // swap quadrants (Top-Left with Bottom-Right)
  A.copyTo(tmp);
  D.copyTo(A);
  tmp.copyTo(D);

  // swap quadrant (Top-Right with Bottom-Left)
  C.copyTo(tmp);
  B.copyTo(C);
  tmp.copyTo(B);
}

int main(int argc, char **argv)
{
  cv::Mat image, padded, complexImage;
  std::vector&lt;cv::Mat&gt; planos;

  image = imread(argv[1], cv::IMREAD_GRAYSCALE);
  if (image.empty())
  {
    std::cout &lt;&lt; "Erro abrindo imagem" &lt;&lt; argv[1] &lt;&lt; std::endl;
    return EXIT_FAILURE;
  }

  // expande a imagem de entrada para o melhor tamanho no qual a DFT pode ser
  // executada, preenchendo com zeros a lateral inferior direita.
  int dft_M = cv::getOptimalDFTSize(image.rows);
  int dft_N = cv::getOptimalDFTSize(image.cols);
  cv::copyMakeBorder(image, padded, 0, dft_M - image.rows, 0, dft_N - image.cols, cv::BORDER_CONSTANT, cv::Scalar::all(0));

  // prepara a matriz complexa para ser preenchida
  // primeiro a parte real, contendo a imagem de entrada
  planos.push_back(cv::Mat_&lt;float&gt;(padded));
  // depois a parte imaginaria com valores nulos
  planos.push_back(cv::Mat::zeros(padded.size(), CV_32F));

  // combina os planos em uma unica estrutura de dados complexa
  cv::merge(planos, complexImage);

  // calcula a DFT
  cv::dft(complexImage, complexImage);
  swapQuadrants(complexImage);

  // planos[0] : Re(DFT(image)
  // planos[1] : Im(DFT(image)
  cv::split(complexImage, planos);

  // calcula o espectro de magnitude e de fase (em radianos)
  cv::Mat magn, fase;
  cv::cartToPolar(planos[0], planos[1], magn, fase, false);
  cv::normalize(fase, fase, 0, 1, cv::NORM_MINMAX);

  // caso deseje apenas o espectro de magnitude da DFT, use:
  cv::magnitude(planos[0], planos[1], magn);

  // some uma constante para evitar log(0)
  // log(1 + sqrt(Re(DFT(image))^2 + Im(DFT(image))^2))
  magn += cv::Scalar::all(1);

  // calcula o logaritmo da magnitude para exibir
  // com compressao de faixa dinamica
  log(magn, magn);
  cv::normalize(magn, magn, 0, 1, cv::NORM_MINMAX);

  // exibe as imagens processadas
  cv::imshow("Imagem", image);
  cv::imshow("Espectro de magnitude", magn);
  cv::imwrite("mag.png", magn);
  cv::imshow("Espectro de fase", fase);
  cv::imwrite("fase.png", fase);

  cv::waitKey();
  return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="s_12">4.2. Filtro Homomórfico</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 11 (Continuação): As respectivas respostas podem ser vistas a seguir (<a href="#mag">figura 31</a> e <a href="#fase">figura 32</a>).</p>
</li>
</ul>
</div>
<div id="mag" class="imageblock">
<div class="content">
<img src="./image/mag.png" alt="mag">
</div>
<div class="title">Figure 31. Magnitude Output</div>
</div>
<div id="fase" class="imageblock">
<div class="content">
<img src="./image/fase.png" alt="fase">
</div>
<div class="title">Figure 32. Fase Output</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 12: A próxima implementação diz respeito ao filtro homomórfico. O filtro homomórfico tem a intenção de melhorar a iluminação irregular de imagens. O algoritmo foi feito considerando o processamento de imagens em tons de cinza.</p>
</li>
</ul>
</div>
<div id="filtrohomomorfico" class="listingblock cpp">
<div class="title">filtrohomomorfico.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-filtrohomomorfico.cpp" data-lang="filtrohomomorfico.cpp">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;opencv2/opencv.hpp&gt;

void swapQuadrants(cv::Mat &amp;image)
{
  cv::Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho ímpar, recorta a região para o maior
  // tamanho par possível (-2 = 1111...1110)
  image = image(cv::Rect(0, 0, image.cols &amp; -2, image.rows &amp; -2));

  int centerX = image.cols / 2;
  int centerY = image.rows / 2;

  // rearranja os quadrantes da transformada de Fourier de forma que
  // a origem fique no centro da imagem
  // A B   -&gt;  D C
  // C D       B A
  A = image(cv::Rect(0, 0, centerX, centerY));
  B = image(cv::Rect(centerX, 0, centerX, centerY));
  C = image(cv::Rect(0, centerY, centerX, centerY));
  D = image(cv::Rect(centerX, centerY, centerX, centerY));

  // swap quadrantes (Top-Left with Bottom-Right)
  A.copyTo(tmp);
  D.copyTo(A);
  tmp.copyTo(D);

  // swap quadrante (Top-Right with Bottom-Left)
  C.copyTo(tmp);
  B.copyTo(C);
  tmp.copyTo(B);
}

void makeFilter(const cv::Mat &amp;image, cv::Mat &amp;filter)
{
  cv::Mat_&lt;float&gt; filter2D(image.rows, image.cols);
  int centerX = image.cols / 2;
  int centerY = image.rows / 2;
  float gammaH = 1.0; // ajuste para realce de iluminação
  float gammaL = 0.5; // ajuste para realce de contraste
  float c = 1.0;      // constante de realce

  for (int i = 0; i &lt; image.rows; i++)
  {
    for (int j = 0; j &lt; image.cols; j++)
    {
      float D = sqrt(pow(i - centerY, 2) + pow(j - centerX, 2));
      // H ( u , v ) = ( γ H − γ L )[ 1 − e − c [ D ( u , v )/ D 0 ] ] + γ L (Gonzales pag. 191)
      float H = (gammaH - gammaL) * (1.0 - exp(-c * pow(D, 2) / pow(centerX, 2))) + gammaL;
      filter2D.at&lt;float&gt;(i, j) = H;
    }
  }

  cv::Mat planes[] = {filter2D, cv::Mat::zeros(filter2D.size(), CV_32F)};
  cv::merge(planes, 2, filter);
}

int main(int argc, char **argv)
{
  cv::Mat image, padded, complexImage;
  std::vector&lt;cv::Mat&gt; planos;

  image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);
  if (image.empty())
  {
    std::cout &lt;&lt; "Erro abrindo imagem " &lt;&lt; argv[1] &lt;&lt; std::endl;
    return EXIT_FAILURE;
  }

  // expande a imagem de entrada para o melhor tamanho no qual a DFT pode ser
  // executada, preenchendo com zeros a lateral inferior direita.
  int dft_M = cv::getOptimalDFTSize(image.rows);
  int dft_N = cv::getOptimalDFTSize(image.cols);
  cv::copyMakeBorder(image, padded, 0, dft_M - image.rows, 0, dft_N - image.cols, cv::BORDER_CONSTANT, cv::Scalar::all(0));

  // prepara a matriz complexa para ser preenchida
  // primeiro a parte real, contendo a imagem de entrada
  planos.push_back(cv::Mat_&lt;float&gt;(padded));
  // depois a parte imaginária com valores nulos
  planos.push_back(cv::Mat::zeros(padded.size(), CV_32F));

  // combina os planos em uma única estrutura de dados complexa
  cv::merge(planos, complexImage);

  // calcula a DFT
  cv::dft(complexImage, complexImage);
  swapQuadrants(complexImage);

  // cria o filtro homomórfico e aplica a filtragem de frequência
  cv::Mat filter;
  makeFilter(complexImage, filter);
  cv::mulSpectrums(complexImage, filter, complexImage, 0);

  // calcula a DFT inversa
  swapQuadrants(complexImage);
  cv::idft(complexImage, complexImage);

  // planos[0] : Re(DFT(image))
  // planos[1] : Im(DFT(image))
  cv::split(complexImage, planos);

  // recorta a imagem filtrada para o tamanho original
  // selecionando a região de interesse (ROI)
  cv::Rect roi(0, 0, image.cols, image.rows);
  cv::Mat result = planos[0](roi);

  // normaliza a parte real para exibição
  cv::normalize(result, result, 0, 1, cv::NORM_MINMAX);

  cv::imshow("Imagem original", image);
  cv::imshow("Imagem filtrada", result);
  cv::imwrite("filtro_homomorfico.png", result * 255);

  cv::waitKey();
  return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 12 (continuação): Considerando a imagem do Biel (<a href="#biel">figura 1</a>) como entrada, veja na <a href="#filtro_homomorfico">figura 33</a> a saída do filtro homomórfico com a correção da iluminação.</p>
</li>
</ul>
</div>
<div id="filtro_homomorfico" class="imageblock">
<div class="content">
<img src="./image/homomorfico.png" alt="homomorfico">
</div>
<div class="title">Figure 33. Relação entre a entrada e saída do algoritmo do Filtro Homomórfico.</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="s_Segmentaçãodeimagens">5. Segmentação de Imagens</h2>
<div class="sectionbody">
<div class="paragraph text-justify">
<p>A segmentação de uma determinada imagem se trata da divisão de áreas dentro da mesma, de acordo com a necessidade de aplicação. Essa divisão normalmente é feita de acordo com dois possíveis quesitos: descontinuidade ou similaridade.
As detecções abruptas na imagem podem ser obtidas através da derivada.</p>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Derivada ordem 1: Produzem bordas mais grossas na detecção.</p>
</li>
</ul>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Derivada ordem 2: Produzem bordas mais finas e resposta mais forte aos detalhes finos (linhas, pontos e ruidos); em transições de rampa e degrau de intensidade possui uma resposta de bordas duplas; o seu sinal pode ser usado para determinar se a transição é de claro para escuro ou de escuro para claro.</p>
</li>
</ul>
</div>
<div class="paragraph text-justify">
<p>Veja a comparação feita no livro do Gonzalez, que trata a diferença entre os efeitos das duas derivadas considerando níveis distintos do ruído gaussiano.</p>
</div>
<div id="bordasderivadas" class="imageblock">
<div class="content">
<img src="./image/bordasderivadas.png" alt="bordasderivadas">
</div>
<div class="title">Figure 34. Resposta das derivadas para diferentes níveis de intensidade do ruido gaussiano em uma imagem (processamento digital de imagens Rafael c. gonzalez)</div>
</div>
<div class="paragraph text-justify">
<p>Como pode ser observado na <a href="#bordasderivadas">figura 34</a>, a primeira coluna representa a entrada com um aumento na intensidade do ruído gaussiano a cada linha. A coluna do meio mostra a resposta da primeira derivada e a segundo coluna refere-se à segunda derivada. Veja que ao aumentar a intensidade do ruído, torna-se inviável a utilização da segunda derivada, por isso, o processo prévio da filtragem é sempre importante.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="s_exemplos3">6. Exemplos do implementação de processamento digital de imagens para detecção de bordas utilizando openCV:</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_4_2_algoritmo_de_canny_e_pontilhismo">4.2. Algoritmo de Canny e Pontilhismo</h3>
<div class="ulist text-justify">
<ul>
<li>
<p>O algoritmo de Canny para detecção de bordas (descontinuidades) em imagens é bem eficiente. Desenvolva um algoritmo capaz de gerar uma obra digital baseada no método de pintura "pontilhismo", utilizando o algoritmo de Canny para detectar as transições no gradiente da imagem, e gerando círculos menores, com raio igual a 1px, nessas regiões com bordas. Os pontos gerados nas demais regiões devem possuir raio variável, assim como o <em>threshold</em> do canny.</p>
</li>
</ul>
</div>
<div id="cannyepontilhismo" class="listingblock cpp">
<div class="title">cannyepontilhismo.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cannyepontilhismo.cpp" data-lang="cannyepontilhismo.cpp">#include &lt;algorithm&gt;
#include &lt;cstdlib&gt;
#include &lt;ctime&gt;
#include &lt;fstream&gt;
#include &lt;iomanip&gt;
#include &lt;iostream&gt;
#include &lt;numeric&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;vector&gt;

#define STEP 1
#define JITTER 3
int RAIO = 3;

int top_slider = 10;
int top_slider_max = 200;

cv::Mat image, border, points;

char TrackbarName[50];

void on_trackbar_canny(int, void *)
{
    cv::Canny(image, border, top_slider, 3 * top_slider);
    cv::imshow("Canny", border);
}

void on_trackbar_pontilhismo(int, void *)
{
    std::vector&lt;int&gt; yrange;
    std::vector&lt;int&gt; xrange;

    int width, height;
    int x, y;

    std::srand(std::time(0));

    width = image.cols;
    height = image.rows;

    xrange.resize(height / STEP);
    yrange.resize(width / STEP);

    std::iota(xrange.begin(), xrange.end(), 0);
    std::iota(yrange.begin(), yrange.end(), 0);

    for (uint i = 0; i &lt; xrange.size(); i++)
    {
        xrange[i] = xrange[i] * STEP + STEP / 2;
    }

    for (uint i = 0; i &lt; yrange.size(); i++)
    {
        yrange[i] = yrange[i] * STEP + STEP / 2;
    }

    points = cv::Mat(height, width, CV_8UC3, cv::Scalar(255, 255, 255)); // Imagem colorida

    // Laço para gerar pontos de raio variável em posições aleatórias
    for (auto i : xrange)
    {
        std::random_shuffle(yrange.begin(), yrange.end());
        for (auto j : yrange)
        {
            // Define as posições para os pontos aleatórios
            x = i + std::rand() % (2 * JITTER) - JITTER + 1;
            y = j + std::rand() % (2 * JITTER) - JITTER + 1;

            // Vetor da cor do pixel em questão, da imagem original
            cv::Vec3b color = image.at&lt;cv::Vec3b&gt;(x, y);

            // Gera pontos com a cor do vetor color, de raio = RAIO (definido pelo usuário)
            cv::circle(points, cv::Point(y, x), RAIO, cv::Scalar(color[0], color[1], color[2]), cv::FILLED, cv::LINE_AA);
        }
    }

    // Laço para gerar pequenos pontos nas posições de bordas de Canny
    for (int i = 0; i &lt; height; i++)
    {
        for (int j = 0; j &lt; width; j++)
        {
            // Vetor da cor do pixel em questão, da imagem original
            cv::Vec3b color = image.at&lt;cv::Vec3b&gt;(i, j);

            // Verifica se a posição é uma borda na resposta de canny
            if (border.at&lt;uchar&gt;(i, j) == 255)
            {
                // Gera pontos com a cor do vetor color, de raio = 1
                cv::circle(points, cv::Point(j, i), 1, cv::Scalar(color[0], color[1], color[2]), cv::FILLED, cv::LINE_AA);
            }
        }
    }
    cv::imshow("Pontilhismo", points);
}

int main(int argc, char **argv)
{

    image = cv::imread(argv[1], cv::IMREAD_COLOR); // Carregar imagem em cores

    if (image.empty())
    {
        std::cout &lt;&lt; "Could not open or find the image" &lt;&lt; std::endl;
        return -1;
    }

    // Canny
    sprintf(TrackbarName, "Threshold inferior");

    cv::namedWindow("Canny", 1);
    cv::createTrackbar(TrackbarName, "Canny",
                       &amp;top_slider,
                       top_slider_max,
                       on_trackbar_canny);

    on_trackbar_canny(top_slider, 0);

    // Pontilhismo
    sprintf(TrackbarName, "Raio");

    cv::namedWindow("Pontilhismo", 1);
    cv::createTrackbar(TrackbarName, "Pontilhismo",
                       &amp;RAIO,
                       10,
                       on_trackbar_pontilhismo);

    on_trackbar_pontilhismo(RAIO, 0);

    cv::waitKey();
    cv::imwrite("pontos.jpg", points);
    cv::imwrite("cannyborders.png", border);
    return 0;
}</code></pre>
</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 13 (Continuação): Veja que o algoritmo acima gera duas <em>trackbartrackbar</em> para alterar o valor do <em>threshold</em> de canny e do raio dos pontos gerados aleatoriamente. Para que os pontos maiores não se sobreponham aos menores desenhados nas transições, o laço responsável por realizar o pontilhismo aleatório ocorre primeiro, permitindo que os pontos de raio 1 sejam pintados na imagem já finalizada com os pontos maiores. Além disso, a referência da coloração dos pixels é a imagem de entrada, não podendo ser alterada durante o processo. Portanto, a pintura é gravada em outra variável chamada "points". Veja na <a href="#EntradaCannyePontilhismo">figura 35</a>, a entrada do algoritmo.</p>
</li>
</ul>
</div>
<div id="EntradaCannyePontilhismo" class="imageblock">
<div class="content">
<img src="./image/maceio.jpg" alt="maceio">
</div>
<div class="title">Figure 35. Entrada para o algoritmo de Canny e Pontilhismo</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 13 (Continuação): A partir dessa entrada, foram obtidas as seguintes respostas variando as bordas de Canny e o raio dos pontos aleatórios:</p>
</li>
</ul>
</div>
<div id="saida1" class="imageblock">
<div class="content">
<img src="./image/saida1.png" alt="saida1">
</div>
<div class="title">Figure 36. <em>Threshold</em> = 0 e Raio = 0</div>
</div>
<div id="saida2" class="imageblock">
<div class="content">
<img src="./image/saida2.png" alt="saida2">
</div>
<div class="title">Figure 37. <em>Threshold</em> = 100 e Raio = 0</div>
</div>
<div id="saida3" class="imageblock">
<div class="content">
<img src="./image/saida3.png" alt="saida3">
</div>
<div class="title">Figure 38. <em>Threshold</em> = 100  e Raio = 2</div>
</div>
<div id="Pontos" class="imageblock">
<div class="content">
<img src="./image/pontos.jpg" alt="pontos">
</div>
<div class="title">Figure 39. Resposta da Arte de Pontilhismo</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Exemplo 13 (Continuação): Note que com o raio aleatório igual a 0, temos apenas os pontos de raio igual a 1px que são gerados nas bordas de Canny definidas. Ao aumentar o tamanho do raio dos pontos aleatórios, os mesmos são desenhados nas regiões que não possuem bordas, ou seja, nas regiões escuras da resposta de Canny. O resultado da arte de pontilhismo pode ser visto na <a href="#Pontos">figura 39</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="s_Projeto">Projeto de PDI: Detecção de Caixas em uma Esteira</h2>
<div class="sectionbody">
<div class="ulist text-justify">
<ul>
<li>
<p>A seguir será mostrado como foi realizado o projeto de Processamento Digital de Imagens, o qual diz respeito a uma problemática simples, mas que de forma semelhante, pode ter aplicações industriais. A ideia geral foi realizar a contagem de caixas que passam por um determinado ponto de uma esteira, levando em consideração apenas a diferença na itensidade do pixel da caixa, comparada com a intensidade do pixel da esteira. Para isso, foi utilizada uma esteira desenvolvida em uma turma do curso técnico em Mecatrônica do IFRN Campus Parnamirim. Veja a imagem da esteira na figura a seguir <a href="#Esteira">esteira</a>.</p>
</li>
</ul>
</div>
<div id="Esteira" class="imageblock">
<div class="content">
<img src="./image/esteira.jpg" alt="esteira">
</div>
<div class="title">Figure 40. Esteira (IFRN - Parnamirim)</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>As caixas foram feitas em origamis de formatos diferentes (<a href="#Caixas">Caixas Origamis</a>).</p>
</li>
</ul>
</div>
<div id="Caixas" class="imageblock">
<div class="content">
<img src="./image/caixas.jpeg" alt="caixas">
</div>
<div class="title">Figure 41. Caixas Origamis</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>A esteira utiliza um motor DC para o acionamento, logo a ideia da implementação foi posicionar a câmera em uma posição fixa acima da esteira, e ligar o motor com as caixas já posicionadas. À medida com que as caixas passam por uma determianada posição central da área de gravação, o algoritmo deve identificar que uma caixa está passando, e durante o vídeo deve ser contada a quantidade de caixa que passou. Como dito anteriormente, a presença de uma caixa na região central da gravação é identificada através do valor de intensidade do pixel no momento analisado, logo foi utilizado o sistema de cores HSI (<em>hue, saturation and intensity</em>) ou HSV (<em>hue, saturation and value</em>), utilizando-se da componente (itensidade). Veja abaixo os vídeos capturados:</p>
</li>
</ul>
</div>
<div class="videoblock">
<div class="title">Vídeo de Entrada 1 - Esteira</div>
<div class="content">
<iframe src="https://www.youtube.com/embed/M5s3YD7yq2c?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
<div class="videoblock">
<div class="title">Vídeo de Entrada 2 - Esteira</div>
<div class="content">
<iframe src="https://www.youtube.com/embed/W2Syf5MaSps?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
<div class="videoblock">
<div class="title">Vídeo de Entrada 3 - Esteira</div>
<div class="content">
<iframe src="https://www.youtube.com/embed/iccK1xhzv8s?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>Como foi dito, a posição do pixel para a detecção da caixa foi descrita na região central da imagem. A referência do valor de intensidade para a diferenciação entre caixa e esteira é: valores acima de 200 correspondem a uma caixa, valores menores que 170 correspondem à esteira. Veja que para os valores entre 200 e 170 não será considerado caixa ou esteira, isso ocorre para evitar falsas interpretações em regiões de transições, onde o valor de intensidade pode ser menor que 200 mas ainda corresponder a uma caixa ou o inverso. Feito isso, o algoritmo deve contar uma caixa sempre que houver transição de esteira para caixa, e mostrar o valor de contagem na saída do terminal. Veja a seguir o algoritmo desenvolido:</p>
</li>
</ul>
</div>
<div id="projeto" class="listingblock cpp">
<div class="title">projeto.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-projeto.cpp" data-lang="projeto.cpp">#include &lt;iostream&gt;
#include "opencv2/opencv.hpp"

int main(int argc, char **argv)
{

    cv::VideoCapture video("video1.mp4");

    if (!video.isOpened())
    {
        std::cout &lt;&lt; "Erro ao abrir o vídeo." &lt;&lt; std::endl;
        return -1;
    }

    // Definições da janela de exibição
    cv::namedWindow("Detecção de Caixas", cv::WINDOW_NORMAL);
    cv::resizeWindow("Detecção de Caixas", 800, 600);

    bool previousValue = false, pausado = false;
    int boxCount = 0;

    while (true)
    {
        if (!pausado)
        {
            cv::Mat frame;
            video &gt;&gt; frame;

            // Verifica se o vídeo terminou (frame == vazio)
            if (frame.empty())
                break;

            cv::Mat hsvFrame;
            // Conversão do sistema de cores RGB para o HSI (matriz, saturação e intensidade)
            cv::cvtColor(frame, hsvFrame, cv::COLOR_BGR2HSV);

            // Define o ponto central na imagem
            cv::Point center(frame.cols / 2, frame.rows / 2); // Ponto central

            // Obtém o Value (intensidade) vetorial no pixel do ponto central criado
            cv::Vec3b centerPixel = hsvFrame.at&lt;cv::Vec3b&gt;(center);

            // Captura o valor inteiro de intensidade
            int currentValueCenter = centerPixel[2];

            // Verifica se o frame anterior era da esteira
            if (currentValueCenter &lt; 170)
            {
                previousValue = false;
            }

            // Verifica se houve mudança da esteira para a caixa
            if (currentValueCenter &gt; 200 &amp;&amp; !previousValue)
            {
                boxCount++;
                previousValue = true;
            }

            // Desenha um marcador no centro da imagem
            cv::drawMarker(frame, center, cv::Scalar(0, 0, 255), cv::MARKER_CROSS, 20, 2);

            // Textos para visualização
            cv::putText(frame, "Numero de Caixas: " + std::to_string(boxCount), cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 0, 255), 2);
            if (previousValue == 1)
                cv::putText(frame, "Caixa detectada!", cv::Point(10, 70), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 0, 255), 2);
            else if (previousValue == 0)
                cv::putText(frame, "Esteira!", cv::Point(10, 70), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 0, 255), 2);

            // Apresenta o frame atual na tela
            cv::imshow("Detecção de Caixas", frame);
        }
        if (cv::waitKey(1) == 'p' || cv::waitKey(1) == 'P') // Verifica se a tecla 'P' foi pressionada
            pausado = !pausado;                             // Inverte o estado do pausado
        if (cv::waitKey(1) == 27)
            break;
    }

    return 0;
}</code></pre>
</div>
</div>
<div class="ulist text-justify">
<ul>
<li>
<p>As respostas do algoritmo para cada vídeo de entrada estão demonstradas abaixo:</p>
</li>
</ul>
</div>
<div class="videoblock">
<div class="title">Resposta do vídeo 1</div>
<div class="content">
<iframe src="https://www.youtube.com/embed/sbMRyyhXr8w?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
<div class="videoblock">
<div class="title">Resposta do vídeo 2</div>
<div class="content">
<iframe src="https://www.youtube.com/embed/ZaGGEVY0kDI?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
<div class="videoblock">
<div class="title">Resposta do vídeo 3</div>
<div class="content">
<iframe src="https://www.youtube.com/embed/h9UGYyr_nWs?rel=0" frameborder="0" allowfullscreen></iframe>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2023-07-18 00:30:05 -0400
</div>
</div>
</body>
</html>